\chapter{Convergence of Matrix Moments}

\section{Convergence in Expectation}


\begin{lemma}[Matrix Powers Entries]
    \label{lem:matrix_powers_entries}
    Let $Y$ be an $n\times n$ matrix and $k \in \mathbb{N}$. Then, for each  $(i, j)$-th
    entry of $Y^{k}$, we have:
    $$
    (Y^{k})_{ij} = \sum_{1 \leq i_2, \ldots ,i_{k} \leq n} Y_{ii_{2}} Y_{i_{2}i_{3}}\ldots Y_{i_{k}j}
    $$
\end{lemma}

\begin{proof}
  We proceed by induction on $k$.

  Our base case is $k=1$, then:
  $$
  Y_n^1 = Y_n \quad \Rightarrow \quad [Y_n^1]_{ij} = Y_{ij},
  $$
  which matches the formula since the summation over zero indices just gives the term $Y_{ij}$.

  Our inductive step is to assume that the formula holds for some $k \ge 1$, i.e.,
  $$
  \left[Y_n^k\right]_{ij} = \sum_{1 \le i_2, \dots, i_k \le n} Y_{i i_2} Y_{i_2 i_3} \cdots Y_{i_k j}.
  $$

  We must show that it holds for $k + 1$. Note that:
  \begin{align*}
  \left[Y_n^{k+1}\right]_{ij}
  &= \sum_{\ell = 1}^n \left[Y_n^k\right]_{i\ell} Y_{\ell j} \\
  &= \sum_{\ell = 1}^n \left( \sum_{1 \le i_2, \dots, i_k \le n} Y_{i i_2} Y_{i_2 i_3} \cdots Y_{i_k \ell} \right) Y_{\ell j} \\
  &= \sum_{1 \le i_2, \dots, i_k, i_{k+1} \le n} Y_{i i_2} Y_{i_2 i_3} \cdots Y_{i_k i_{k+1}} Y_{i_{k+1} j}.
  \end{align*}

  Thus, the formula holds for $k + 1$.

  By induction, the result holds for all $k \ge 1$.
\end{proof}



\begin{definition}[Matrix Multi Index]
    \label{def:matrix_multi_index}
    Let $\mathbf{i} \in[n]^k$ be a $k$-index, $\mathbf{i}=\left(i_1, i_2, \ldots, i_k\right)$.
    Let $Y$ be a symmetric matrix. The matrix multi index $Y_{\mathbf{i}}$ is defined as:
    $$
    Y_{\mathbf{i}} = Y_{i_{1}i_{2}} Y_{i_{2}i_{3}} \ldots Y_{i_{k}i_{1}}
    $$
\end{definition}

\begin{lemma}[Matrix Powers Trace]
  \label{lem:matrix_powers_trace}
  \uses{lem:matrix_powers_entries,def:matrix_multi_index}
  Let $Y$ be an $n\times n$ matrix and $k \in \mathbb{N}$. Then, the trace of $Y^{k}$ is given by:
  $$
  \Tr[Y^{k}] = \sum_{\mathbf{i} \in [n]^k} Y_{\mathbf{i}}.
  $$
\end{lemma}

\begin{proof}
  We can use the result from Lemma \ref{lem:matrix_powers_entries} to compute the trace of $Y^k$:
  \begin{align*}
  &\Tr[Y^{k}] = \sum_{i=1}^{n} (Y^{k})_{ii} = \sum_{i=1}^{n} (\sum_{1\leq i_{2}, \ldots i_{k} \leq n} Y_{i i_{2}} Y_{i_{2}i_{3}} \ldots Y_{i_{k} i}) \\
  &= \sum_{1\leq i_{1}, i_{2}, \ldots, i_{k} \leq n} Y_{i_{1} i_{2}} Y_{i_{2} i_{3}} \ldots Y_{i_{k} i_{1}}.
\end{align*}

\end{proof}


\begin{lemma}[Trace of Expectation of Matrix]
    \label{lem:trace_expectation_of_matrix}
    \uses{lem:matrix_powers_trace,def:matrix_multi_index}
    $$
    \bE(\Tr(\mathbf{Y}_{n}^{k})) = \sum_{\mathbf{i} \in [n]^{k}} \bE(Y_{i})
    $$
\end{lemma}

\begin{proof}
  By linearity of expectation.
\end{proof}


\begin{lemma}[Matrix Multi Index and Graph Equivalence]
    \label{lem:multi_index_graph_equivalence}
    \uses{def:matrix_multi_index,def:graph_walk_multi_index}
    Let $\mathbf{i} \in [n]^k$ be a $k$-index, $\mathbf{i}=\left(i_1, i_2, \ldots, i_k\right)$. Then
     $$
     Y_{\mathbf{i}} = Y_{i_{1}i_{2}} Y_{i_{2}i_{3}} \ldots Y_{i_{k}i_{1}} = \prod_{w \in w_{\mathbf{i}}} Y_{w}
    $$
\end{lemma}

\begin{proof}
    We see from definition $\ref{def:graph_walk_multi_index}$ that the path is defined as:
    $$
    w_{\mathbf{i}} = ((i_1, i_2),(i_2, i_3), \ldots,(i_{k-1}, i_k),(i_k, i_1)).
    $$
    if we use each each edge $w \in w_{\mathbf{i}}$, due to symmetry, we can write the product:
    $$
    \prod_{w\in w_{\mathbf{i}}} Y_{w} = Y_{\{i_{1}, i_{2}\}} Y_{\{i_{2}, i_{3}\}} \ldots Y_{\{i_{k-1}, i_{k}\}} Y_{\{i_{k}, i_{1}\}} = Y_{i_{1}i_{2}} Y_{i_{2}i_{3}} \ldots Y_{i_{k}i_{1}} = Y_{\mathbf{i}}
    $$
    as required.
\end{proof}


\begin{lemma}[Graph Walk and Graph Count Equivalence]
    \label{lem:graph_walk_count_equivalence}
    \uses{def:graph_edge_count,lem:multi_index_graph_equivalence}
    Let $\mathbf{i} \in[n]^k$ be a $k$-index, $\mathbf{i}=\left(i_1, i_2, \ldots, i_k\right)$.
    Let $Y$ be a symmetric matrix. Then, we have the following:
    $$
    Y_{\mathbf{i}} =  \prod_{1 \leq i \leq j \leq n} Y_{ij}^{w_{\mathbf{i}}(\{i, j\})}.
    $$
\end{lemma}

\begin{proof}
  Using lemma \ref{lem:multi_index_graph_equivalence}, we already have that $Y_{\mathbf{i}} = \prod_{w \in w_{\mathbf{i}}} Y_{w}$. We consider the following cases for each $(i, j)$:\\\\
  \textbf{$(i, j) \notin w_{\mathbf{i}}$}: In this case, the entry $Y_{ij}^{w_{\mathbf{i}}(\{i, j\})} = 1$, making no contribution to the product. \\\\
  \textbf{$(i, j) \in w_{\mathbf{i}}$}: In this case, the entry $Y_{ij}^{w_{\mathbf{i}}(\{i, j\})}$ is equal to the number of times the unordered edge $\{i, j\}$ appears in the path $w_{\mathbf{i}}$. \\\\
  These two cover all possibilities, so putting them together we obtain
  $$
  Y_{\mathbf i}
        \;=\;
        \prod_{1\le i\le j\le n}
            Y_{ij}^{\,w_{\mathbf i}(\{i,j\})}.
  $$
  Indeed, if $(i,j)\notin w_{\mathbf i}$ then $w_{\mathbf i}(\{i,j\})=0$ and the corresponding factor contributes $Y_{ij}^{0}=1$, and if $(i,j)\in w_{\mathbf i}$ (hence also $(j,i)$ if $j<i$), the exponent $w_{\mathbf i}(\{i,j\})$ counts exactly how many times the unordered edge $\{i,j\}$ appears in the walk, so the factor is $Y_{ij}^{\,w_{\mathbf i}(\{i,j\})}$.

  Because every unordered pair $\{i,j\}$ with $1\le i\le j\le n$ is covered by one of these two cases and the product lists each edge exactly once.
\end{proof}

\begin{lemma}[Expectation of Matrix Multi Index]
    \label{lem:expectation_matrix_multi_index}
    \uses{def:graph_edge_count,def:graph_self_edges,def:graph_walk_multi_index,def:graph_connecting_edges,def:matrix_multi_index,lem:graph_walk_count_equivalence}
    Let $\mathbf{i} \in[n]^k$ be a $k$-index, $\mathbf{i}=\left(i_1, i_2, \ldots, i_k\right)$. Let $Y$ be a symmetric matrix and let $\{Y_{ij}\}_{1\le i\le j}$ be independent random variables, with $\{Y_{ii}\}_{i\ge 1}$ identically distributed and $\{Y_{ij}\}_{1\le i<j}$ identically distributed. Then, we have the following:
    $$
    \bE(Y_{\mathbf{i}}) = \prod_{e_s \in E_{\mathbf{i}}^s} \bE(Y_{11}^{w_{\mathbf{i}}(e_s)}) \cdot \prod_{e_c \in E_{\mathbf{i}}^c} \bE(Y_{12}^{w_{\mathbf{i}}(e_c)}).
    $$
\end{lemma}

\begin{proof}
  Because each $Y_{ij}$ is independent, we can write:
  $$
  \bE(Y_{\mathbf{i}}) = \bE\left(\prod_{1 \leq i \leq j \leq n} Y_{ij}^{w_{\mathbf{i}}(\{i, j\})}\right)
  = \prod_{1 \leq i \leq j \leq n} \bE(Y_{ij}^{w_{\mathbf{i}}(\{i, j\})})
  $$
  using lemma \ref{lem:graph_walk_count_equivalence}. Consider the following cases for each $(i, j)$ (we assume each $(i, j) \in w_{\mathbf{i}}$ since if they aren't, then $w_{\mathbf{i}}(i, j) = 0$ and this contributes nothing to the product):\\\\
  $\mathbf{i = j}$: in this case, we have $Y_{ij} = Y_{ii}$, and therefore the edge $(i, i) \in E_{\mathbf{i}}^{s}$. Since each $Y_{ii}$ is identically distributed for all $i$, we have:
  $$
  \bE(Y_{ii}) = \bE(Y_{11})
  $$
  so the factor in the product above becomes $\bE(Y_{ij}^{w_{\mathbf{i}}(\{i, j\})}) = \bE(Y_{11}^{w_{\mathbf{i}}(i, i)})$.\\\\
  $\mathbf{i < j}$: in this case, we have  $Y_{ij} \in E_{\mathbf{i}}^{c}$. Since each non diagonal entry $Y_{ij}$ is identically distributed for all $i \neq j$ (and by symmetry $Y_{ij} = Y_{ji}$), we have:
  $$
  \bE(Y_{ij}) = \bE(Y_{12})
  $$
  so the factor in the product above becomes $\bE(Y_{ij}^{w_{\mathbf{i}}(\{i, j\})}) = \bE(Y_{12}^{w_{\mathbf{i}}(i, j)})$.\\\\
  Plugging both of these cases into the earlier product over $E_{\mathbf{i}}^{c}$ and $E_{\mathbf{i}}^{s}$, we have:
  $$
  \prod_{1 \leq i \leq j \leq n} \bE(Y_{ij}^{w_{\mathbf{i}}(\{i, j\})}) = \prod_{e_s \in E_{\mathbf{i}}^s} \bE(Y_{11}^{w_{\mathbf{i}}(e_s)}) \cdot \prod_{e_c \in E_{\mathbf{i}}^c} \bE(Y_{12}^{w_{\mathbf{i}}(e_c)})
  $$
  as required.
\end{proof}


\begin{definition}[Product of Expectation of Matrix Multi Index]
    \label{def:prod_expectation_matrix_multi_index}
    \uses{lem:expectation_matrix_multi_index,def:graph_walk_multi_index}
    Let $\mathbf{i} \in [n]^{k}$ be a $k$-index, $\mathbf{i} = (i_1, i_2, \ldots, i_{k})$. We define
    $\Pi(w_{\mathbf{i}})$ as follows:
    $$
    \Pi (w_{\mathbf{i}}) = \prod_{e_s \in E_{\mathbf{i}}^s} \bE(Y_{11}^{w_{\mathbf{i}}(e_s)}) \cdot \prod_{e_c \in E_{\mathbf{i}}^c} \bE(Y_{12}^{w_{\mathbf{i}}(e_c)}) = \bE(Y_{\mathbf{i}}).
    $$
\end{definition}


\begin{lemma}[$\mathbf{i} \sim \mathbf{j} \Rightarrow \mathbb{E}(Y_\mathbf{i}) = \mathbb{E}(Y_\mathbf{j})$ : R-1-7 : lem:eq\_equiv\_eq\_expect]
  \label{lem:eq_equiv_eq_expect}
  \uses{def:graph_walk_equiv,lem:expectation_matrix_multi_index,def:graph_walk_multi_index}
  Given two $k$-indexes $\mathbf{i} = (i_1,...,i_k)$ and $\mathbf{j} = (j_1,...,j_k)$,
  suppose $w_{\mathbf{i}} \sim w_{\mathbf{j}}$ under \ref{def:graph_walk_equiv}.
  Then $\bE (Y_\mathbf{i}) = \bE (Y_{\mathbf{j}})$.
\end{lemma}

\begin{proof}
  Let $\varphi$ be the permutation that maps $w_\mathbf{i}$ to $w_{\mathbf{j}}$ in the equivalence
  relation. Given $Y_\mathbf{i} = Y_{i_1 i_2}Y_{i_2 i_3} \cdots Y_{i_{k-1} i_k}Y_{i_k i_1}$, we have
  \[
  Y_{\mathbf{j}} = Y_{j_1 j_2}Y_{j_2 j_3} \cdots Y_{j_{k-1} j_k}Y_{j_k j_1}
  = Y_{\varphi(i_1) \varphi(i_2)}Y_{\varphi(i_2) \varphi(i_3)} \cdots Y_{\varphi(i_{k-1}) \varphi(i_k)}Y_{\varphi(i_k) \varphi(i_1)}.
  \]
  Observe that $\{ i_{\lambda_l},i_{\lambda_{l+1}} \}$ is a singleton and only if
  $\{ \varphi(i_{\lambda_l}),\varphi(i_{\lambda_{l+1}}) \}$ is a singleton.
  The fact that $\{ i_{\lambda_l},i_{\lambda_{l+1}} \} = \{ i_{\lambda_\mu},i_{\lambda_{\mu+1}} \}$
  if and only if $\{ \varphi(i_{\lambda_l}),\varphi(i_{\lambda_{l+1}}) \} = \{ \varphi(i_{\lambda_\mu}),\varphi(i_{\lambda_{\mu+1}}) \}$
  completes the proof.
\end{proof}


\begin{lemma}[Partitioning into double summation : R-1-10 : lem:equation\_4.5\_1]
  \label{lem:equation_4.5_1}
  \uses{def:g_k,lem:trace_expectation_of_matrix,lem:eq_equiv_eq_expect}
  \[
  \bE \Tr (\mathbf{Y}_n^k)
  = \sum_{w \in \mathcal{G}_k} \sum_{\substack{\mathbf{i} \in [n]^k \\ w_\mathbf{i} = w}} \bE (Y_\mathbf{i}).
  \]
\end{lemma}

\begin{proof}
  This follows from `partitioning' the summation appearing in Lemma \ref{lem:trace_expectation_of_matrix} using the equivalence relation defined in Definition \ref{def:g_k_equiv}.
\end{proof}


\begin{definition}[$\Pi (G,w)$: R-1-11 : def:Pi.G.w]
  \label{def:Pi.G.w}
  \uses{def:g_k,def:prod_expectation_matrix_multi_index,lem:eq_equiv_eq_expect}
  Given $w \in \mathcal{G}_k$, let $w_{\mathbf{i}}$ be an element of its equivalence class. We define
  \[
  \Pi (w) = \mathbb{E}(Y_\mathbf{i}).
  \]
\end{definition}


\begin{lemma}[Re-indexing the sum with counting argument : R-1-12 : lem:equation\_4.5\_2]
  \label{lem:equation_4.5_2}
  \uses{lem:equation_4.5_1,lem:eq_equiv_eq_expect,def:Pi.G.w}
  \[
  \bE \Tr (\mathbf{Y}_n^k) = \sum_{w \in \mathcal{G}_k} \Pi (w) \cdot \# \{ \mathbf{i} \in [n]^k : w_\mathbf{i} = w \}.
  \]
\end{lemma}

\begin{proof}
  This follows from re-indexing the sum of Lemma \ref{lem:equation_4.5_1} by using Lemma \ref{lem:eq_equiv_eq_expect} and Lemma \ref{lem:lem_4.3}.
\end{proof}


\begin{lemma}[Re-introducing the renormalization factor : R-1-13 : lem:equation\_4.5\_3]
  \label{lem:equation_4.5_3}
  \uses{lem:equation_4.5_2,lem:lem_4.3}
  \[
  \frac{1}{n} \bE \Tr (\mathbf{X}_n^k) = \sum_{w \in \mathcal{G}_k} \Pi (w) \cdot \frac{n (n-1) \cdots (n - |V_w| + 1)}{n^{k/2+1}}.
  \]
\end{lemma}

\begin{proof}
  Combining with the renormalization factor $n^{-1}$ of Proposition \ref{???} gives
  \[
  \frac{1}{n} \bE \Tr (\mathbf{X}_n^k) = \frac{1}{n^{k/2+1}} \bE \Tr (\mathbf{Y}_\mathbf{i}^k).
  \]
  Substituting the term $\bE \Tr (\mathbf{Y}_\mathbf{i}^k)$ with the expression in Equation \ref{lem:equation_4.5_2} gives
  \[
  \frac{1}{n} \bE \Tr (\mathbf{X}_n^k) = \sum_{\substack{(G,w) \in \mathcal{G}_k}} \Pi (G,w) \cdot \frac{n (n-1) \cdots (n - |G_w| + 1)}{n^{k/2+1}}.
  \]
\end{proof}


\begin{lemma}[$\Pi (G,w) = 0$ : R-1-15 : lem:Pi.prod\_eq\_zero\_if\_w\_le\_two]
  \label{lem:Pi.prod_eq_zero_if_w_le_two}
  \uses{def:g_k,def:prod_expectation_matrix_multi_index,def:edge_count_w,def:Pi.G.w}
  Given $w \in \mathcal{G}_k$, suppose there exists an edge $e \in E$ in which it is traversed only
  once in the walk $w$, i.e $1 \in EC_w$. Then
  \[
  \Pi (w) = 0.
  \]
\end{lemma}

\begin{proof}
  Let $(G,w) \in \mathcal{G}_k$ and let $\mathbf{j}$ be the $k$-index generated by $(G,w)$. Suppose there exists an edge $e \in E_\mathbf{j}$ such that $w_\mathbf{j}(e) = 1$.
  This means, in Lemma \ref{lem:expectation_matrix_multi_index}, a singleton term $\bE (Y_{ij}^{w_\mathbf{j}(e)}) = \bE (Y_{ij})$ appears.
  The rest of the proof follows from the assumption of Proposition \ref{???} that $\bE (Y_{ij}) = 0$ for every $i$ and $j$.
\end{proof}


\begin{lemma}[Simplifying the summation with the fact $\Pi (G,w) = 0$ in certain cases: R-1-16 : lem:equation\_4.8]
  \label{lem:equation_4.8}
  \uses{def:g_k_ge_2,lem:equation_4.5_3,lem:Pi.prod_eq_zero_if_w_le_two}
  \[
  \frac{1}{n} \bE \Tr (\mathbf{X}_n^k)
  = \sum_{w \in \mathcal{G}_{k, w \geq 2}} \Pi (w) \cdot \frac{n (n-1) \cdots (n - |V_w| + 1)}{n^{k/2+1}}.
  \]

\end{lemma}

\begin{proof}
  This follows from applying the result of Lemma \ref{lem:Pi.prod_eq_zero_if_w_le_two} to Lemma \ref{lem:equation_4.5_3}.
\end{proof}


\begin{lemma}
  \label{lem:asc_factorial_product}
  $n(n-1)\cdots (n-|V|+1) \le n^{|V|}$.
\end{lemma}

\begin{proof}
  Use Nat.ascFactorial\_eq\_div. Or prove directly.
\end{proof}


\begin{lemma}
  \label{lem:bounded_map}
  \uses{lem:asc_factorial_product,lem:vertex_bound,lem:equation_4.8}
  The sequence $n\mapsto \frac1n\bE\Tr(X_n^k)$ is bounded.
\end{lemma}

\begin{proof}
  \notready
  The only part that depends on $n$ is the big fraction. Since we only care about $w \ge 2$, $|G_w| \le k/2 + 1$.
  Use the fact that the product $n(n-1)\cdots (n-|G|+1)$ is asymptotically equal to $n^{|G|}$ to
  conclude that the fraction is bounded and doesn't explode.
\end{proof}


\begin{lemma}
  \label{lem:odd_ratio_bound}
  \notready
  \uses{lem:odd_vertex_bound,lem:asc_factorial_product}
  Suppose $k$ odd. Then, $\frac{n(n-1)\cdots(n-|V_w|+1)}{n^{k/2+1}} \le \frac{1}{\sqrt{n}}$.
\end{lemma}

\begin{proof}
  \notready
  %prove
\end{proof}


\begin{proposition}
  \label{prop:odd_case}
  \notready
  \uses{lem:odd_ratio_bound,lem:equation_4.8}
  Suppose $k$ odd. Then, $\lim_{n\to\infty} \frac{1}{n}\bE\Tr(X_n^k) = 0$.
\end{proposition}

\begin{proof}
  \notready
  Since $|G_w|\le \#E+1 \le k/2+1$ and $|G_w|$ is an integer, it follows that $|G_w|\le (k-1)/2+1 = k/2 + 1/2$.  Hence, in this case, all the terms in the (finite $n$-independent) sum in Equation 4.8 are $O(n^{-1/2})$
\end{proof}


\begin{proposition}
  \label{prop:g_difference_bound}
  \notready
  \uses{def:g_k,def:g_k_ge_2,lem:graph_set_finite,def:special_set_g,lem:asc_factorial_product}
  $|\sum_{\mathcal{G}_{k}, w \ge 2} \Pi (w) \cdot \frac{n (n-1) \cdots (n - |G_w| + 1)}{n^{k/2+1}}
  - \sum_{\mathcal{G}_k^{k/2+1}}\Pi (w) \cdot \frac{n (n-1) \cdots (n - |G_w| + 1)}{n^{k/2+1}}|
  \le |\mathcal{G}_k|/n$.
\end{proposition}

\begin{proof}
  \notready
  %proof
\end{proof}


\begin{proposition}%[Equation 4.9 in \cite{Kemp2013RMTNotes}]
  \label{prop:trace_ev_special_g}
  \notready
  \uses{def:special_set_g,prop:g_difference_bound,lem:equation_4.8}
  $\frac1n\bE\Tr(X_n^k) = \sum_{w\in\mathcal{G}^{k/2+1}_k} \Pi(w) \cdot \frac{n(n-1)\cdots(n-|G_w|+1)}{n^{k/2+1}} + O_k(n^{-1})$
  %edit: remove big O notation
\end{proposition}

\begin{proof}
  \notready
  If $|G_w| < k/2 + 1$, then there is at least one more $n$ in the denominator than the numerator.
\end{proof}


\begin{proposition}
  \label{lem:fraction_limit_one}
  \notready
  \uses{lem:asc_factorial_product} %uses some lower bound stuff? might need to do more
  $\lim_{n\to\infty}\frac{n^{k/2}}{n(n-1)\cdots(n-k/2+1)} = 1$.
\end{proposition}

\begin{proof}
  \notready
  %proof
  some lower bound stuff + other stuff?
\end{proof}


\begin{proposition}
  \label{prop:trace_ev_limit_equals_sum}
  \notready
  \uses{def:special_set_g,lem:fraction_limit_one,prop:trace_ev_special_g,lem:bounded_map}
  $\lim_{n\to\infty}\bE\Tr(X_n^k) = \sum_{w\in\mathcal{G}^{k/2+1}_k} \Pi(w)$
\end{proposition}

\begin{proof}
  \notready
  Proof: use the fact that $|G_w|=k/2+1$ and $n(n-1)\cdots(n-k/2+1) \sim n^{k/2+1}$. Limit as n approaches infinity of $O(n^{-1/2})$ is 0.
\end{proof}


\begin{lemma}
  \label{lem:prod_expansion}
  \notready
  \uses{def:special_set_g,def:prod_expectation_matrix_multi_index}
  For $w\in\mathcal{G}^{k/2+1}_k$, $\Pi(w) = \prod_{e_c\in E^c} \bE(Y_{12}^{w(e_c)})$
\end{lemma}

\begin{proof}
  \notready
  Follows directly.
\end{proof}


\begin{lemma}
  \label{lem:w_2_case}
  \notready
  \uses{def:special_set_g,lem:prod_expansion}
  $\prod_{e_c\in E^c} \bE(Y_{12}^{w(e_c)}) = \prod_{e_c\in E^c} \bE(Y_{12}^2)$
\end{lemma}

\begin{proof}
  \notready
  Follows directly.
\end{proof}


\begin{lemma}
  \label{lem:def_t_rewrite}
  \notready
  \uses{}
  $\bE(Y_{12}^2) = t$
\end{lemma}

\begin{proof}
  \notready
  Follows directly.
\end{proof}


\begin{lemma}
  \label{lem:e_equals_k_over_two}
  \notready
  \uses{def:special_set_g,lem:special_g_edge_count}
  $t^{|E_w|} = t^{k/2}$
\end{lemma}

\begin{proof}
  \notready
  Follows directly.
\end{proof}


\begin{proposition}%[Equation 4.10 in \cite{Kemp2013RMTNotes}]
  \label{prop:product_g_w_to_exponential}
  \notready
  \uses{lem:prod_expansion, lem:w_2_case, lem:def_t_rewrite, lem:e_equals_k_over_two}
  $\Pi(w) = t^{k/2}$.
\end{proposition}

\begin{proof}
  \notready
  Proof slightly outdated.

  Let $(G,w)\in\mathcal{G}^{k/2+1}_k$.  Since $w$ traverses each edge exactly twice, the number of edges in $G$ is $k/2$.  Since the number of vertices is $k/2+1$, Exercise (Prop) 4.3.1 shows that $G$ is a tree.  In particular there are no self-edges (as we saw already in Proposition 4.4).

  1st equality: definition right after equation 4.4 in notes
  2nd equality: proposition 4.4 (w < 3) and previous lemma (w = 1 --> 0)
  3nd equality: definition (from main proposition)
  4th equality: number of edges is k/2.
\end{proof}


\begin{proposition}%[Proposition 4.11 in \cite{Kemp2013RMTNotes}]
  \label{prop:trace_ev_limit_equals_t_special_g}
  \notready
  \uses{prop:trace_ev_limit_equals_sum,prop:product_g_w_to_exponential}
  $\lim_{n\to\infty} \bE\Tr(X_n^k) = t^{k/2}\cdot|\mathcal{G}_k^{k/2+1}|$
\end{proposition}

\begin{proof}
  \notready
  Follows directly from 4.7.5 and 4.8.
\end{proof}


%% BIG PROPOSITION
\begin{proposition}[Proposition 4.1 in \cite{Kemp2013RMTNotes}]
  \label{prop:matrix_moments_convergence}
  \notready
  \uses{prop:trace_ev_limit_equals_t_special_g,prop:odd_case,prop:graph_Catalan_number}
  \lean{wignerMatrixMomentEvenExpectationLimit, wignerMatrixMomentOddExpectation}
  Let $\{Y_{ij}\}_{1\le i\le j}$ be independent random variables, with $\{Y_{ii}\}_{i\ge 1}$ identically distributed and $\{Y_{ij}\}_{1\le i<j}$ identically distributed.  Suppose that $r_k = \max\{\bE(|Y_{11}|^k),\bE(|Y_{12}|^k)\} <\infty$ for each $k\in\bN$.  Suppose further than $\bE(Y_{ij})=0$ for all $i,j$ and set $t=\bE(Y_{12}^2)$.  If $i>j$, define $Y_{ij} \equiv Y_{ji}$, and let $\mathbf{Y}_n$ be the $n\times n$ matrix with $[\mathbf{Y}_n]_{ij} = Y_{ij}$ for $1\le i,j\le n$.  Let $\mathbf{X}_n = n^{-1/2}\mathbf{Y}_n$ be the corresponding Wigner matrix.  Then
\[
\lim_{n\to\infty} \frac{1}{n}\bE\Tr(\mathbf{X}_n^k) = \begin{cases}
  t^{k/2}C_{k/2}, & k\text{ even} \\
  0, & k\text{ odd}
\end{cases}.
\]
\end{proposition}

\begin{proof}
\notready
\end{proof}


\section{Convergence in Probability}


\begin{lemma}[Variance Trace Expansion]
    \label{lem:variance_expansion}
    \uses{lem:trace_expectation_of_matrix}
    \notready
    Let $\mathbf{Y}_{n}$ be an $n \times n$ symmetric matrix with independent entries, where $\{Y_{ij}\}_{1\le i\le j}$ are independent random variables, with $\{Y_{ii}\}_{i\ge 1}$ identically distributed and $\{Y_{ij}\}_{1\le i<j}$ identically distributed, and let $\mathbf{X}_{n} = n^{-1 / 2}\mathbf{Y}_{n}$ be the corresponding Wigner matrix. Then:
    $$
    \operatorname{Var}\left(\frac{1}{n}\Tr(\mathbf{X}_{n}^{k})\right) = \frac{1}{n^{k+2}} \sum_{\mathbf{i}, \mathbf{j} \in [n]^{k}} [\bE(Y_{\mathbf{i}} Y_{\mathbf{j}}) - \bE(Y_{\mathbf{i}})\bE(Y_{\mathbf{j}})]
    $$
\end{lemma}

\begin{proof}
    \notready
    Expanding the variance by definition, we get:
    $$
    \operatorname{Var}\left(\frac{1}{n}\Tr(\mathbf{X}_{n}^{k})\right) = \bE[\frac{1}{n} \cdot \frac{1}{n^{\frac{k}{2}}} \Tr(\mathbf{Y}_{n}^{k})]^2 - (\bE[\frac{1}{n}\cdot \frac{1}{n^{\frac{k}{2}}} \Tr(\mathbf{Y})_{n}^{k}])^2
    $$
    use the linearity of expectation to factor out $\frac{1}{n^{k+2}}$ from both expectations:
    $$
    \bE[\frac{1}{n} \cdot \frac{1}{n^{\frac{k}{2}}} \Tr(\mathbf{Y}_{n}^{k})]^2 - (\bE[\frac{1}{n}\cdot \frac{1}{n^{\frac{k}{2}}} \Tr(\mathbf{Y})_{n}^{k}])^2 = \frac{1}{n^{k+2}} \{\bE[\operatorname{Tr}(\mathbf{Y}_{n}^{k})]^2 - (\bE \operatorname{Tr}(\mathbf{Y}_{n}^{k}))^2\}
    $$
    using \ref{lem:trace_expectation_of_matrix}, we can expand and square:
\end{proof}


\begin{definition}[R-2-1 : def:common\_val\_prod\_of]
  \notready
  \label{def:common_val_prod_of}
  \uses{def:matrix_multi_index,def:ordered_triple}
  Given an ordered triple $(G_{\mathbf{i}\#\mathbf{j}},w_\mathbf{i},w_\mathbf{j})$ generated by two $k$-indexes $\mathbf{i}$ and $\mathbf{j}$, we define
  \[
  \pi(G_{\mathbf{i}\#\mathbf{j}},w_\mathbf{i},w_\mathbf{j}) = \mathbb{E}(Y_\mathbf{i} Y_\mathbf{j}) - \mathbb{E}(Y_\mathbf{i}) \mathbb{E}(Y_\mathbf{j}).
  \]
\end{definition}


\begin{lemma}[R-2-3-4 : lem:common\_val\_eq\_of\_index\_pair\_rel]
  \notready
  \label{lem:common_val_eq_of_index_pair_rel}
  \uses{def:index_pair_rel,def:matrix_multi_index,lem:eq_equiv_eq_expect}
  Let $\mathbf{i}_\lambda$ and $\mathbf{j}_\lambda$ be $k$-indexes for each $\lambda=1,2$ such that $(\mathbf{i}_1,\mathbf{j}_1) = (\mathbf{i}_2,\mathbf{j}_2)$.
  Then $\bE (Y_{\mathbf{i}_1}Y_{\mathbf{j}_1}) = \bE (Y_{\mathbf{i}_1}Y_{\mathbf{j}_2})$.
\end{lemma}

\begin{proof}
  This follows a similar reasoning as in Lemma \ref{lem:eq_equiv_eq_expect}.
\end{proof}


\begin{lemma}[R-2-4 : lem:sum\_eq\_sum\_over\_classes]
  \notready
  \label{lem:sum_eq_sum_over_classes}
  \uses{lem:variance_expansion,def:graph_walk_triple_rel}
  \[
  \text{Var} \biggl(\frac{1}{n} \Tr (\mathbf{X}_n^k) \biggl)
  = \frac{1}{n^{k+2}} \sum_{(G,w,w') \in \mathcal{G}_{k,k}} \sum_{\substack{\mathbf{i},\mathbf{j} \in [n]^k \\ (G_{\mathbf{i}\#\mathbf{j}},w_\mathbf{i},w_\mathbf{j}) = (G,w,w')}} [\mathbb{E}(Y_\mathbf{i} Y_\mathbf{j}) - \mathbb{E}(Y_\mathbf{i}) \mathbb{E}(Y_\mathbf{j})].
  \]
\end{lemma}

\begin{proof}
  This follows from `partitioning' the summation appearing in Lemma \ref{lem:variance_expansion} using the equivalence relation defined in Definition \ref{def:graph_walk_triple_rel}.
% Given an ordered triple $(G_{\mathbf{i}\#\mathbf{j}},w_\mathbf{i},w_\mathbf{j})$ generated by two $k$-indexes $\mathbf{i}$ and $\mathbf{j}$, and $(G,w,w') \in \mathcal{G}_{k,k}$,
%  only one of $(G_{\mathbf{i}\#\mathbf{j}},w_\mathbf{i},w_\mathbf{j}) = (G,w,w')$ or $(G_{\mathbf{i}\#\mathbf{j}},w_\mathbf{i},w_\mathbf{j}) \neq (G,w,w')$ holds.
%  Hence, the partition of the summation is well-defined.
\end{proof}


\begin{definition}[R-2-5-1 : def:common\_val\_prod]
  \notready
  \label{def:common_val_prod}
  \uses{def:matrix_multi_index,def:graph_walk_triple_set,def:index_pair}
  Given $(G,w,w')$, let $(\mathbf{i},\mathbf{j})$ be an ordered pair of $k$-indexes generated by $w$ and $w'$.
  We define
  \[
  \pi(G,w,w') = \mathbb{E}(Y_\mathbf{i} Y_\mathbf{j}) - \mathbb{E}(Y_\mathbf{i}) \mathbb{E}(Y_\mathbf{j}).
  \]
\end{definition}


\begin{lemma}[R-2-5-2 : lem:inner\_sum\_eq\_common\_val\_prod\_mul\_card]
  \notready
  \label{lem:inner_sum_eq_common_val_prod_mul_card}
  \uses{lem:sum_eq_sum_over_classes,def:common_val_prod,lem:common_val_prod_eq_of_graph_walk_triple_rel}
  \[
  \text{Var} \biggl(\frac{1}{n} \Tr (\mathbf{X}_n^k) \biggl)
  = \frac{1}{n^{k+2}} \sum_{(G,w,w') \in \mathcal{G}_{k,k}} \pi(G,w,w')
\cdot \# \bigl\{ (\mathbf{i},\mathbf{j}) \in [n]^{2k} : (G_{\mathbf{i} \# \mathbf{j}},w_\mathbf{i},w_\mathbf{j}) = (G,w,w') \bigl\}.
  \]
\end{lemma}

\begin{proof}
  This follows from re-indexing the sum of Lemma \ref{lem:sum_eq_sum_over_classes} using Lemma \ref{lem:common_val_prod_eq_of_graph_walk_triple_rel}.
\end{proof}


\begin{lemma}[R-2-8 : lem:expect\_mul\_eq\_prod\_expect\_edgewise\_of\_indep]
  \notready
  \label{lem:expect_mul_eq_prod_expect_edgewise_of_indep}
  \uses{def:edgeCountPair,lem:expectation_matrix_multi_index,def:graph_walk_triple_single_edges,def:graph_walk_triple_connected_edges}
  \[
  \mathbb{E} (Y_\mathbf{i}Y_\mathbf{j})
  = \prod_{e_s \in E^s_{\mathbf{i} \# \mathbf{j}}} \mathbb{E} (Y_{11}^{w_{\mathbf{i} \# \mathbf{j}}(e_s)}) \cdot \prod_{e_c \in E^c_{\mathbf{i} \# \mathbf{j}}} \mathbb{E} (Y_{12}^{w_{\mathbf{i} \# \mathbf{j}}(e_c)}).
  \]
\end{lemma}

\begin{proof}
  This follows from Lemma \ref{lem:expectation_matrix_multi_index} and the independency of random variables.
\end{proof}


\begin{lemma}[R-2-12.1 : lem:expect\_pow\_edge\_count\_pair\_le]
  \notready
  \label{lem:expect_pow_edge_count_pair_le}
  \uses{def:ordered_triple,def:edgeCountPair,lem:sum_count_edge_pair_eq_length_add_length}
  For any $k$-indexes $\mathbf{i}$ and $\mathbf{j}$, there exists $\lambda \in \mathbb{N}$ such that
  \[
  \mathbb{E} (Y_{11}^{w_{\mathbf{i} \# \mathbf{j} (e)}}) \leq r_\lambda
  \]
  for every $e \in E_{\mathbf{i} \# \mathbf{j}}$.
\end{lemma}

\begin{proof}
  Let $(G_{\mathbf{i}\#\mathbf{j}},w_\mathbf{i},w_\mathbf{j})$ be the ordered triple generated by the two $k$-indexes $\mathbf{i}$ and $\mathbf{j}$.
  By construction, there are finite number of edges $e \in E_{\mathbf{i} \# \mathbf{j}}$.
  Moreover, there are finite number of integer values the counting function $w_{\mathbf{i} \# \mathbf{j}}(\cdot)$ can take over $E_{\mathbf{i} \# \mathbf{j}}$.
  This implies we can choose the maximum element of the set
  \[
  \mathscr{E} := \{ \mathbb{E} (Y_{11}^\lambda) : \lambda = w_{\mathbf{i} \# \mathbf{j}}(e) \text{ for some } e \in E_{\mathbf{i} \# \mathbf{j}} \},
  \]
  and therefore $\lambda \in \mathbb{N}$ so that $\mathbb{E}(Y_{11}^\lambda) = \max \mathscr{E}$.
  Using the fact that $\mathbb{E}(Z) \leq \mathbb{E}(|Z|)$ for any random variable $Z$,
  \[
  \mathbb{E} (Y_{11}^{w_{\mathbf{i} \# \mathbf{j} (e)}}) \leq \max\{ \mathbb{E}(|Y_{11}^\lambda|), \mathbb{E}(|Y_{12}^\lambda|) \} = r_\lambda.
  \]
\end{proof}


\begin{lemma}[R-2-12.2 : lem:expect\_pow\_edge\_count\_pair\_le\_off]
  \notready
  \label{lem:expect_pow_edge_count_pair_le_off}
  \uses{def:ordered_triple,def:edgeCountPair,lem:sum_count_edge_pair_eq_length_add_length}
  For any $k$-indexes $\mathbf{i}$ and $\mathbf{j}$, there exists $\lambda \in \mathbb{N}$ such that
  \[
  \mathbb{E} (Y_{12}^{w_{\mathbf{i} \# \mathbf{j} (e)}}) \leq r_\lambda
  \]
  for every $e \in E_{\mathbf{i} \# \mathbf{j}}$.
\end{lemma}

\begin{proof}
  This follows an identical reasoning as in Lemma \ref{lem:expect_pow_edge_count_pair_le}.
\end{proof}


\begin{lemma}[R-2-13 : lem:expect\_mul\_le\_const]
  \notready
  \label{lem:expect_mul_le_const}
  \uses{lem:expect_mul_eq_prod_expect_edgewise_of_indep,lem:expect_pow_edge_count_pair_le,lem:expect_pow_edge_count_pair_le_off}
  For any $k$-indexes $\mathbf{i}$ and $\mathbf{j}$, there exists $M_1 \in \mathbb{R}$ such that
  \[
  \mathbb{E} (Y_\mathbf{i}Y_\mathbf{j}) \leq M_1.
  \]
\end{lemma}

\begin{proof}
  By Lemma \ref{lem:expect_mul_eq_prod_expect_edgewise_of_indep}, we have
  \[
  \mathbb{E} (Y_\mathbf{i}Y_\mathbf{j})
  = \prod_{e_s \in E^s_{\mathbf{i} \# \mathbf{j}}} \mathbb{E} (Y_{11}^{w_{\mathbf{i} \# \mathbf{j}}(e_s)}) \cdot \prod_{e_c \in E^c_{\mathbf{i} \# \mathbf{j}}} \mathbb{E} (Y_{12}^{w_{\mathbf{i} \# \mathbf{j}}(e_c)}).
  \]
  By Lemma \ref{lem:expect_pow_edge_count_pair_le}, there exists $\lambda_1 \in \mathbb{N}$ so that $\mathbb{E} (Y_{11}^{w_{\mathbf{i} \# \mathbf{j} (e)}}) \leq r_n$ for every $e \in E_{\mathbf{i} \# \mathbf{j}}$.
  On the other hand, by Lemma \ref{lem:expect_pow_edge_count_pair_le_off}, there exists $\lambda_2 \in \mathbb{N}$ so that $\mathbb{E} (Y_{12}^{w_{\mathbf{i} \# \mathbf{j} (e)}}) \leq r_m$ for every $e \in E_{\mathbf{i} \# \mathbf{j}}$.
  Then
  \[ \mathbb{E} (Y_\mathbf{i}Y_\mathbf{j})
  = \prod_{e_s \in E^s_{\mathbf{i} \# \mathbf{j}}} \mathbb{E} (Y_{11}^{w_{\mathbf{i} \# \mathbf{j}}(e_s)}) \cdot \prod_{e_c \in E^c_{\mathbf{i} \# \mathbf{j}}} \mathbb{E} (Y_{12}^{w_{\mathbf{i} \# \mathbf{j}}(e_c)})
  \leq 2k \cdot \max\{r_{\lambda_1},r_{\lambda_2}\}.
  \]
  Setting $M_1 := 2k \cdot \max\{r_{\lambda_1},r_{\lambda_2}\}$ satisfies the problem.
\end{proof}


\begin{lemma}[R-2-14 : lem:expect\_pow\_edge\_count\_le]
  \notready
  \label{lem:expect_pow_edge_count_le}
  \uses{def:graph_edge_count,lem:abs_w_i_eq_k}
  For any $k$-index $\mathbf{i}$, there exists $\lambda \in \mathbb{N}$ such that
  \[
  \mathbb{E} (Y_{11}^{w_{\mathbf{i}}(e)}) \leq r_\lambda.
  \]
  for every $e \in E_{\mathbf{i} \# \mathbf{j}}$.
\end{lemma}

\begin{proof}
  This follows a similar reasoning as in Lemma \ref{lem:expect_pow_edge_count_pair_le} with the counting function $w_\mathbf{i}(\cdot)$.
\end{proof}


\begin{lemma}[R-2-15 : lem:expect\_pow\_edge\_count\_le\_off]
  \notready
  \label{lem:expect_pow_edge_count_le_off}
  \uses{def:graph_edge_count,lem:abs_w_i_eq_k}
  For any $k$-index $\mathbf{i}$, there exists $\lambda \in \mathbb{N}$ such that
  \[
  \mathbb{E} (Y_{12}^{w_{\mathbf{i}}(e)}) \leq r_\lambda.
  \]
  for every $e \in E_\mathbf{i}$.
\end{lemma}

\begin{proof}
  This follows a similar reasoning as in Lemma \ref{lem:expect_pow_edge_count_pair_le} with the counting function $w_\mathbf{i}(\cdot)$.
\end{proof}


\begin{lemma}[R-2-16 : lem:expect\_le\_const]
  \notready
  \label{lem:expect_le_const}
  \uses{lem:expectation_matrix_multi_index,lem:expect_pow_edge_count_le,lem:expect_pow_edge_count_le_off}
  For any $k$-indexes $\mathbf{i}$, there exists $M_2 \in \mathbb{R}$ such that
  \[
  \mathbb{E} (Y_\mathbf{i}) \leq M_2.
  \]
\end{lemma}

\begin{proof}
  This follows an identical reasoning as in Lemma \ref{lem:expect_pow_edge_count_pair_le}.
\end{proof}


\begin{lemma}[R-2-17 : lem:abs\_expect\_mul\_sub\_mul\_expect\_le]
  \notready
  \label{lem:abs_expect_mul_sub_mul_expect_le}
  \uses{lem:expect_mul_le_const,lem:expect_le_const}
  For any $k$-indexes $\mathbf{i}$ and $\mathbf{j}$, there exists $M_{2k} \in \mathbb{R}_{\geq 0}$ such that
  \[
  | \mathbb{E} (Y_\mathbf{i}Y_\mathbf{j}) -  \mathbb{E}(Y_\mathbf{i}) \mathbb{E}(Y_\mathbf{j}) |
  \leq 2 M_{2k}.
  \]
\end{lemma}

\begin{proof}
  Combining the result of Lemma \ref{lem:expect_mul_le_const} and Lemma \ref{lem:expect_le_const} gives
  \[
  | \mathbb{E} (Y_\mathbf{i}Y_\mathbf{j}) -  \mathbb{E}(Y_\mathbf{i}) \mathbb{E}(Y_\mathbf{j}) |
  \leq | \mathbb{E} (Y_\mathbf{i}Y_\mathbf{j}) | + | \mathbb{E}(Y_\mathbf{i})| | \mathbb{E}(Y_\mathbf{j}) |
  \leq M_1 + M_2^{(\mathbf{i})} \cdot M_2^{(\mathbf{j})},
  \]
  where $M_2^{(\mathbf{i})}$ and $M_2^{(\mathbf{j})}$ are the upper bounds acquired by Lemma \ref{lem:expect_le_const} with repsect to $\mathbf{i}$ and $\mathbf{j}$, repsectively.
  Setting $M_{2k} := \max\{ M_1, M_2^{(\mathbf{i})} \cdot M_2^{(\mathbf{j})} \}$ satisfies the problem.
\end{proof}


\begin{proposition}
  \label{prop:var_trace_as_sum}
  \notready
  \uses{lem:inner_sum_eq_common_val_prod_mul_card}
  \[ \Var\left( \frac1n\Tr(X_n^k)\right) = \sum_{(G,w,w')\in \mathcal{G}_{k,k}\atop w+w'\ge 2} \pi(G,w,w')\cdot\frac{\#\left\{(i,{j})\in [n]^{2k}\colon (G_{i\#j},w_{i},w_{j}) = (G,w,w')\right\}}{n^{k+2}}. \]
\end{proposition}

\begin{proof}
  \notready
  By construction, every edge in the joined graph $G_{{i}\#{j}}$ is traversed at least once by the union of the two paths $w_{i}$ and $w_{j}$.  Suppose that $e$ is an edge that is traversed only {\em once}.  This means that $w_{{i}\#{j}}(e) = 1$, and so it follows that the two values $w_{i}(e),w_{j}(e)$ are $\{0,1\}$.  Hence, the above expansion and the fact that $\bE(Y_{11})=\bE(Y_{12})=0$ show that $\pi(G_{{i}\#{j}},w_{i},w_{j}) = 0$ in this case.
\end{proof}


\begin{lemma}
  \label{lem:simplified_var_trace_as_sum}
  \uses{prop:var_trace_as_sum, lem:g_w_w_count}
  \notready
  \[ \Var\left( \frac1n\Tr({X}_n^k)\right) = \sum_{(G,w,w')\in \mathcal{G}_{k,k}\atop w+w'\ge 2} \pi(G,w,w')\cdot\frac{n(n-1)\cdots (n-|G|+1)}{n^{k+2}}. \]
\end{lemma}

\begin{proof}
  \notready
  Follows directly.
\end{proof}


\begin{proposition}
  \label{prop:var_upper_bound}
  \uses{prop:vertex_edge_inequality, lem:simplified_var_trace_as_sum, lem:abs_expect_mul_sub_mul_expect_le, lem:g_k_k_edge_count_maximum, def:common_val_prod}
  \notready
  \[ \Var\left( \frac1n\Tr({X}_n^k)\right) \le \sum_{(G,w,w')\in\mathcal{G}_{k,k}\atop w+w'\ge 2} \pi(G,w,w')\cdot \frac{n^{k+1}}{n^{k+2}} \le \frac1n\cdot 2M_{2k}\cdot \#\mathcal{G}_{k,k}. \]
\end{proposition}

\begin{proof}
  \notready
  Appealing again to \ref{prop:vertex_edge_inequality}, it follows that $|G|\le k+1$.  Hence, $n(n-1)\cdots(n-|G|+1) \le n^{|G|} \le n^{k+1}$
\end{proof}


\begin{theorem}
  \label{thm:wigner_law_matrix_moments}
  \uses{prop:var_upper_bound}
  \notready
  Theorem 2.4. (Unsure if it goes in this doc.)
\end{theorem}

\begin{proof}
  \notready
  The (potentially enormous) number $B_k=2M_{2k}\cdot\#\mathcal{G}_{k,k}$ is independent of $n$, and so we have already proved that the variance is $=O_k(1/n)$.
\end{proof}


\begin{lemma}
    \label{lem:elimination_kp1}
    \notready
    \uses{lem:G_leq_k, prop:var_upper_bound}

    \[ \Var\left( \frac1n\Tr(\mathbf{X}_n^k)\right) \le \sum_{(G,w,w')\in\mathcal{G}_{k,k}\atop w+w'\ge 2, |G| \leq k} \pi(G,w,w')\cdot \frac{n^{k}}{n^{k+2}} \le \frac{1}{n^2}\cdot 2M_{2k}\cdot \#\mathcal{G}_{k,k}. \]
\end{lemma}


\begin{proposition}[Proposition 4.5 in \cite{Kemp2013RMTNotes}]
  \label{prop:matrix_moments_convergence_probability}
  \uses{lem:elimination_kp1}
  \lean{wignerMatrixMomentsVarianceLimit}
  \notready
  Let $\{Y_{ij}\}_{1 \leq i \leq j}$ be independent random variables, with $\{Y_{ii}\}_{i\geq 1}$ identically distributed and $\{Y_{ij}\}_{1 \leq i < j}$ identically distributed. Suppose that $r_k = \max\{\bE(|Y_{11}|^k),\bE(|Y_{12}|^k)\} < \infty$ for each $k\in\bN$. Suppose further than $\bE(Y_{ij})=0$ for all $i,j$. If $i>j$, define $Y_{ij} \equiv Y_{ji}$, and let $\mathbf{Y}_n$ be the $n\times n$ matrix with $[\mathbf{Y}_n]_{ij} = Y_{ij}$ for $1\le i,j\le n$. Let $\mathbf{X}_n = n^{-1/2}\mathbf{Y}_n$ be the corresponding Wigner matrix. Then
  $$
  \operatorname{Var}(\frac{1}{n}\Tr(\mathbf{X}_{n}^{k})) = O_{k}(\frac{1}{n^2})
  $$
\end{proposition}
