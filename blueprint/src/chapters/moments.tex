\chapter{Convergence of Matrix Moments}
\section{Convergence in Expectation}

\begin{lemma}[Matrix Powers Entries]
    \label{lem:matrix_powers_entries}
    \notready
    Let $Y$ be an $n\times n$ matrix and $k \in \mathbb{N}$. Then, for each  $(i, j)$-th entry of $Y^{k}$, we have:
    $$
    (Y^{k})_{ij} = \sum_{1 \leq i_2, \ldots ,i_{k} \leq n} Y_{ii_{2}} Y_{i_{2}i_{3}}\ldots Y_{i_{k}j}
    $$
\end{lemma}

\begin{proof}
\notready
We proceed by induction on $k$.

Our base case is $k=1$, then:
$$
Y_n^1 = Y_n \quad \Rightarrow \quad [Y_n^1]_{ij} = Y_{ij},
$$
which matches the formula since the summation over zero indices just gives the term $Y_{ij}$.

Our inductive step is to assume that the formula holds for some $k \ge 1$, i.e.,
$$
\left[Y_n^k\right]_{ij} = \sum_{1 \le i_2, \dots, i_k \le n} Y_{i i_2} Y_{i_2 i_3} \cdots Y_{i_k j}.
$$

We must show that it holds for $k + 1$. Note that:
\begin{align*}
\left[Y_n^{k+1}\right]_{ij}
&= \sum_{\ell = 1}^n \left[Y_n^k\right]_{i\ell} Y_{\ell j} \\
&= \sum_{\ell = 1}^n \left( \sum_{1 \le i_2, \dots, i_k \le n} Y_{i i_2} Y_{i_2 i_3} \cdots Y_{i_k \ell} \right) Y_{\ell j} \\
&= \sum_{1 \le i_2, \dots, i_k, i_{k+1} \le n} Y_{i i_2} Y_{i_2 i_3} \cdots Y_{i_k i_{k+1}} Y_{i_{k+1} j}.
\end{align*}

Thus, the formula holds for $k + 1$.

By induction, the result holds for all $k \ge 1$.
\end{proof}

\begin{lemma}[Matrix Powers Trace]
    \label{lem:matrix_powers_trace}
    \notready
    \uses{lem:matrix_powers_entries}
    Let $Y$ be an $n\times n$ matrix and $k \in \mathbb{N}$. Then, the trace of $Y^{k}$ is given by:
    $$
    \Tr[Y^{k}] = \sum_{1 \leq i_1, i_2, \ldots, i_k \leq n} Y_{i_1 i_2} Y_{i_2 i_3} \cdots Y_{i_k i_1}.
    $$
\end{lemma}

\begin{proof}
\notready
We can use the result from Lemma \ref{lem:matrix_powers_entries} to compute the trace of $Y^k$:
\begin{align*}
&\Tr[Y^{k}] = \sum_{i=1}^{n} (Y^{k})_{ii} = \sum_{i=1}^{n} (\sum_{1\leq i_{2}, \ldots i_{k} \leq n} Y_{i i_{2}} Y_{i_{2}i_{3}} \ldots Y_{i_{k} i}) \\
&= \sum_{1\leq i_{1}, i_{2}, \ldots, i_{k} \leq n} Y_{i_{1} i_{2}} Y_{i_{2} i_{3}} \ldots Y_{i_{k} i_{1}}.
\end{align*}

\end{proof}

\begin{definition}[Graphs from Multi Index]
    \label{def:graph_multi_index}
    \notready
    \uses{def:}
    Let $\mathbf{i} \in[n]^k$ be a $k$-index, $\mathbf{i}=\left(i_1, i_2, \ldots, i_k\right)$. A graph $G_{\mathbf{i}}$ is defined as follows: the vertices $V_{\mathbf{i}}$ are the distinct elements of
    $$\left\{i_1, i_2, \ldots, i_k\right\},$$
     and the edges $E_{\mathbf{i}}$ are the distinct pairs among
    $$\left\{i_1, i_2\right\},\left\{i_2, i_3\right\}, \ldots,\left\{i_{k-1}, i_k\right\},\left\{i_k, i_1\right\}.$$
\end{definition}

\begin{definition}[Definition 4.2 in \cite{Kemp2013RMTNotes}]
  \label{def:graph_path}
  \notready
  \uses{def:graph_multi_index}
  Let $\mathbf{i} \in[n]^k$ be a $k$-index, $\mathbf{i}=\left(i_1, i_2, \ldots, i_k\right)$. the path $w_{\mathbf{i}}$ is the sequence
$$
w_{\mathbf{i}}=\left(\left\{i_1, i_2\right\},\left\{i_2, i_3\right\}, \ldots,\left\{i_{k-1}, i_k\right\},\left\{i_k, i_1\right\}\right)
$$
of edges from $E_{\mathbf{i}}$
\end{definition}

\begin{definition}[Graph Edge Count]
    \label{def:graph_edge_count}
    \notready
    \uses{def:graph_multi_index, def:graph_path}
    Let $\mathbf{i} \in[n]^k$ be a $k$-index, $\mathbf{i}=\left(i_1, i_2, \ldots, i_k\right)$. For any edge $e=\{i,j\}$ from $E_{\mathbf{i}}$, we define the edge count $w_{\mathbf{i}}(e)$ as the number of times each edge $e$ is traversed, and if $(i, j) \notin E_{\mathbf{i}}$, then $w_{\mathbf{i}}(\{i, j\}) = 0$.
\end{definition}

\begin{definition}[Matrix Multi Index]
    \label{def:matrix_multi_index}
    \notready
    Let $\mathbf{i} \in[n]^k$ be a $k$-index, $\mathbf{i}=\left(i_1, i_2, \ldots, i_k\right)$. Let $Y$ be a symmetric matrix. The matrix multi index $Y_{\mathbf{i}}$ is defined as:
    $$
    Y_{\mathbf{i}} = Y_{i_{1}i_{2}} Y_{i_{2}i_{3}} \ldots Y_{i_{k}i_{1}}
    $$
\end{definition}

\begin{lemma}[Matrix Multi Index and Graph Equivalence]
    \label{lem:multi_index_graph_equivalence}
    \notready
    \uses{def:matrix_multi_index, def:graph_path}
    Let $\mathbf{i} \in[n]^k$ be a $k$-index, $\mathbf{i}=\left(i_1, i_2, \ldots, i_k\right)$. Let $Y$ be a symmetric matrix. Then, we have the following:
     $$
     Y_{\mathbf{i}} = Y_{i_{1}i_{2}} Y_{i_{2}i_{3}} \ldots Y_{i_{k}i_{1}} = \prod_{w \in w_{\mathbf{i}}} Y_{w}
    $$
\end{lemma}

\begin{proof}
\notready
    We see from definition $\ref{def:graph_path}$ that the path is defined as:
    $$
    w_{\mathbf{i}} = (\{i_{1}, i_{2}\}, \{i_{2}, i_{3}\}, \ldots, \{i_{k-1}, i_{k}\}, \{i_{k}, i_{1}\}).
    $$
    if we use each each edge $w \in w_{\mathbf{i}}$, due to symmetry, we can write the product:
    $$
    \prod_{w\in w_{\mathbf{i}}} Y_{w} = Y_{\{i_{1}, i_{2}\}} Y_{\{i_{2}, i_{3}\}} \ldots Y_{\{i_{k-1}, i_{k}\}} Y_{\{i_{k}, i_{1}\}} = Y_{i_{1}i_{2}} Y_{i_{2}i_{3}} \ldots Y_{i_{k}i_{1}} = Y_{\mathbf{i}}
    $$
    as required.
\end{proof}

\begin{lemma}[Graph Walk and Graph Count Equivalence]
    \label{lem:graph_walk_count_equivalence}
    \notready
    \uses{def:graph_graph_path, def:graph_edge_count, def:matrix_multi_index, lem:multi_index_graph_equivalence}
    Let $\mathbf{i} \in[n]^k$ be a $k$-index, $\mathbf{i}=\left(i_1, i_2, \ldots, i_k\right)$. Let $Y$ be a symmetric matrix. Then, we have the following:
     $$
     Y_{\mathbf{i}} = \prod_{w \in w_{\mathbf{i}}} Y_{w} = \prod_{1 \leq i \leq j \leq n} Y_{ij}^{w_{\mathbf{i}}(\{i, j\})}.
    $$
\end{lemma}

\begin{proof}
\notready
Using lemma \ref{lem:multi_index_graph_equivalence}, we already have that $Y_{\mathbf{i}} = \prod_{w \in w_{\mathbf{i}}} Y_{w}$. We consider the following cases for each $(i, j)$:\\\\
\textbf{$(i, j) \notin w_{\mathbf{i}}$}: In this case, the entry $Y_{ij}^{w_{\mathbf{i}}(\{i, j\})} = 1$, making no contribution to the product. \\\\
\textbf{$(i, j) \in w_{\mathbf{i}}$}: In this case, the entry $Y_{ij}^{w_{\mathbf{i}}(\{i, j\})}$ is equal to the number of times the unordered edge $\{i, j\}$ appears in the path $w_{\mathbf{i}}$. \\\\
These two cover all possibilities, so putting them together we obtain
$$
Y_{\mathbf i}
      \;=\;
      \prod_{1\le i\le j\le n}
          Y_{ij}^{\,w_{\mathbf i}(\{i,j\})}.
$$
Indeed, if $(i,j)\notin w_{\mathbf i}$ then $w_{\mathbf i}(\{i,j\})=0$ and the corresponding factor contributes $Y_{ij}^{0}=1$, and if $(i,j)\in w_{\mathbf i}$ (hence also $(j,i)$ if $j<i$), the exponent $w_{\mathbf i}(\{i,j\})$ counts exactly how many times the unordered edge $\{i,j\}$ appears in the walk, so the factor is $Y_{ij}^{\,w_{\mathbf i}(\{i,j\})}$.

Because every unordered pair $\{i,j\}$ with $1\le i\le j\le n$ is covered by one of these two cases and the product lists each edge exactly once.
\end{proof}

\begin{definition}[Self Edges]
    \label{def:graph_self_edges}
    \notready
    \uses{def:graph_multi_index}
    Let $\mathbf{i} \in[n]^k$ be a $k$-index. Given graph $G_{\mathbf{i}}$, define the self-edges $E_{\mathbf{i}}^{s}$ as:
    $$
    \{\{i, i\} \in E_{\mathbf{i}}\},
    $$
    the set of edges where both vertices are the same.
\end{definition}

\begin{definition}[Connecting Edges]
    \label{def:graph_connecting_edges}
    \notready
    \uses{def:graph_multi_index}
    Let $\mathbf{i} \in[n]^k$ be a $k$-index. Given graph $G_{\mathbf{i}}$, define the connecting-edges $E_{\mathbf{i}}^{c}$ as:
    $$
    \{\{i, j\} \in E_{\mathbf{i}} : i \neq j\}
    $$
\end{definition}

\begin{lemma}[Expectation of Matrix Multi Index]
    \label{lem:expectation_matrix_multi_index}
    \notready
    \uses{def:matrix_multi_index, def:graph_edge_count, def:graph_self_edges, def:graph_connecting_edges}
    Let $\mathbf{i} \in[n]^k$ be a $k$-index, $\mathbf{i}=\left(i_1, i_2, \ldots, i_k\right)$. Let $Y$ be a symmetric matrix and let $\{Y_{ij}\}_{1\le i\le j}$ be independent random variables, with $\{Y_{ii}\}_{i\ge 1}$ identically distributed and $\{Y_{ij}\}_{1\le i<j}$ identically distributed. Then, we have the following:
    $$
    \bE(Y_{\mathbf{i}}) = \prod_{e_s \in E_{\mathbf{i}}^s} \bE(Y_{11}^{w_{\mathbf{i}}(e_s)}) \cdot \prod_{e_c \in E_{\mathbf{i}}^c} \bE(Y_{12}^{w_{\mathbf{i}}(e_c)}).
    $$
\end{lemma}

\begin{lemma}[Trace of Expectation of Matrix]
    \label{lem:trace_expectation_of_matrix}
    \notready
    \uses{lem:expectation_matrix_multi_index}
    Let $\mathbf{Y}_{n}$ be an $n \times n$ symmetric matrix with independent entries, where $\{Y_{ij}\}_{1\le i\le j}$ are independent random variables, with $\{Y_{ii}\}_{i\ge 1}$ identically distributed and $\{Y_{ij}\}_{1\le i<j}$ identically distributed. Then, for any $k$-index $\mathbf{i} \in [n]^k$, we have:
    $$
    \bE(\Tr(\mathbf{Y}_{n}^{k})) = \sum_{1 \leq i_1, i_2, \ldots, i_k \leq n} \bE(Y_{i_1 i_2} Y_{i_2 i_3} \cdots Y_{i_k i_1}) = \sum_{\mathbf{i} \in [n]^{k}} \bE(Y_{i})
    $$
\end{lemma}

\begin{proof}
\notready
Because each $Y_{ij}$ is independent, we can write:
$$
\bE(Y_{\mathbf{i}}) = \bE\left(\prod_{1 \leq i \leq j \leq n} Y_{ij}^{w_{\mathbf{i}}(\{i, j\})}\right) = \prod_{1 \leq i \leq j \leq n} \bE(Y_{ij}^{w_{\mathbf{i}}(\{i, j\})})
$$
using lemma \ref{lem:graph_walk_count_equivalence}. Consider the following cases for each $(i, j)$ (we assume each $(i, j) \in w_{\mathbf{i}}$ since if they aren't, then $w_{\mathbf{i}}(i, j) = 0$ and this contributes nothing to the product):\\\\
$\mathbf{i = j}$: in this case, we have $Y_{ij} = Y_{ii}$, and therefore the edge $(i, i) \in E_{\mathbf{i}}^{s}$. Since each $Y_{ii}$ is identically distributed for all $i$, we have:
$$
\bE(Y_{ii}) = \bE(Y_{11})
$$
so the factor in the product above becomes $\bE(Y_{ij}^{w_{\mathbf{i}}(\{i, j\})}) = \bE(Y_{11}^{w_{\mathbf{i}}(i, i)})$.\\\\
$\mathbf{i < j}$: in this case, we have  $Y_{ij} \in E_{\mathbf{i}}^{c}$. Since each non diagonal entry $Y_{ij}$ is identically distributed for all $i \neq j$ (and by symmetry $Y_{ij} = Y_{ji}$), we have:
$$
\bE(Y_{ij}) = \bE(Y_{12})
$$
so the factor in the product above becomes $\bE(Y_{ij}^{w_{\mathbf{i}}(\{i, j\})}) = \bE(Y_{12}^{w_{\mathbf{i}}(i, j)})$.\\\\
Plugging both of these cases into the earlier product over $E_{\mathbf{i}}^{c}$ and $E_{\mathbf{i}}^{s}$, we have:
 $$
 \prod_{1 \leq i \leq j \leq n} \bE(Y_{ij}^{w_{\mathbf{i}}(\{i, j\})}) = \prod_{e_s \in E_{\mathbf{i}}^s} \bE(Y_{11}^{w_{\mathbf{i}}(e_s)}) \cdot \prod_{e_c \in E_{\mathbf{i}}^c} \bE(Y_{12}^{w_{\mathbf{i}}(e_c)})
$$
as required.

\end{proof}

\begin{definition}[Product of Expectation of Matrix Multi Index]
    \label{def:expectation_matrix_multi_index}
    \notready
    \uses{def:matrix_multi_index, def:graph_edge_count, def:graph_self_edges, def:graph_connecting_edges, def:graph_multi_index, def:graph_path}
    Let $\mathbf{i} \in [n]^{k}$ be a $k$-index, $\mathbf{i} = (i_1, i_2, \ldots, i_{k})$. Let $Y$ be a symmetric matrix and let $\{Y_{ij}\}_{1\le i\le j}$ be independent random variables, with $\{Y_{ii}\}_{i\ge 1}$ identically distributed and $\{Y_{ij}\}_{1\le i<j}$ identically distributed. We define $\Pi(G_{\mathbf{i}}), w_{\mathbf{i}}$ as follows:
    $$
    \Pi (G_{\mathbf{i}}, w_{\mathbf{i}}) = \prod_{e_s \in E_{\mathbf{i}}^s} \bE(Y_{11}^{w_{\mathbf{i}}(e_s)}) \cdot \prod_{e_c \in E_{\mathbf{i}}^c} \bE(Y_{12}^{w_{\mathbf{i}}(e_c)}) = \bE(Y_{\mathbf{i}}).
    $$
\end{definition}







\begin{lemma}
  \label{lem:graph_walk_le_k}
  \uses{def:graph_multi_index,def:graph_path,def:graph_edge_count}
  For any $k$-index $\mathbf{i}$, the connected graph $G_\mathbf{i}$ has at most $k$ vertices. Furthermore
  \[
  |w_\mathbf{i}| \equiv \sum_{e \in E_\mathbf{i}} w_\mathbf{i}(e) = k.
  \]
\end{lemma}
\begin{proof}

  Foremost, since the number of vertices of the graph $G_\mathbf{i}$ 
  are the number of distinct elements of the $k$-index $\mathbf{i}$, it clearly follows that $|G| \leq k$.
  On the other hand, given an edge $e \in E_\mathbf{i}$, by Definition \ref{def:graph_edge_count}, $w_i(e)$ as the number of times the walk $w_\mathbf{i}$ traversed $e$. 

  Since $|w_\mathbf{i}| = k$ by construction, it follows that
  \[
  |w_\mathbf{i}| \equiv \sum_{e \in E_\mathbf{i}} w_\mathbf{i}(e) = k.
  \]
\end{proof}
%---------%
% Motivated by these conditions, we define $\mathcal{G}_k$:
%---------%
\begin{definition}
  \label{def:g_k}
  \uses{def:graph_multi_index,def:graph_path,def:graph_edge_count}
  Let $\mathcal{G}_k$ denote the set of all ordered pairs $(G,w)$ where $G = (V,E)$ is a connected graph with at most $k$ vertices, and
  $w$ is a closed walk covering $G$ satisfying $|w| = k$.
\end{definition}
%---------%

% We can count the set of $k$-indexes in Equation \ref{* *}: 
% For any $(G,w) \in \mathcal{G}_k$, an index with that corresponding graph $G$ and walk $w$ is completely determined by assigning which distinct values of $[n]$ appear at the vertices of $G$:
%---------%
% The definition below proposes an alternate definition of $\mathcal{G}_k$ along with the equivalence relation. 
%\begin{definition}
%  \label{def:g_k}
%  \notready
%  \uses{}

%  %We propose an alternate (and perhaps more explicit) construction of $\mathcal{G}_k$. 
%  We define $\mathcal{G}_k$ as the set of equivalence classes of the set $\{ (G_\mathbf{i},w_\mathbf{i}) : \mathbf{i} \in [n]^k \text{ and } n \in \mathbb{N} \}$, 
%  where the equivalence relation is defined as: $(G_\mathbf{i},w_\mathbf{i}) \sim (G_{\mathbf{i}^*},w_{\mathbf{i}^*})$ 

%  if and only if there exists a bijection $\varphi$ from the set of entries $\mathbf{i}$ onto the set of entries $\mathbf{i}^*$ such that
%  \[
%  \mathbf{i} = (i_1,...,i_k) \,\, \Longleftrightarrow \,\, \mathbf{i}^* = \bigl( \varphi(i_1),\varphi(i_2),...,\varphi(i_k) \bigl).
%  \]
%  We denote an element of $\mathcal{G}_k$ as $(G,w)$.
%\end{definition}
%---------%
\begin{lemma}
  \label{lem:equal_equiv_class_equal_expectation}
  \notready
  \uses{def:graph_multi_index,def:graph_path,def:matrix_multi_index}

  Given two $k$-indexes $\mathbf{i} = (i_1,...,i_k)$ and $\mathbf{i}^* = (j_1,...,j_k)$, 

  suppose there exists a bijection $\varphi$ from the set of entries $\mathbf{i}$ onto the set of entries $\mathbf{i}^*$ such that
  \[
  \mathbf{i} = (i_1,...,i_k) \,\, \Longleftrightarrow \,\, \mathbf{i}^* = \bigl( \varphi(i_1),\varphi(i_2),...,\varphi(i_k) \bigl).
  \]
  Then $\bE (Y_\mathbf{i}) = \bE (Y_{\mathbf{i}^*})$.
\end{lemma}
\begin{proof}
  It suffices to show that $Y_\mathbf{i}$ and $Y_{\mathbf{i}^*}$ represent the same number of, respectively, self-edges and connecting edges.
  Given $Y_\mathbf{i} = Y_{i_1 i_2}Y_{i_2 i_3} \cdots Y_{i_{k-1} i_k}Y_{i_k i_1}$,
  \[
  Y_{\mathbf{i}^*} = Y_{j_1 j_2}Y_{j_2 j_3} \cdots Y_{j_{k-1} j_k}Y_{j_k j_1} 
  = Y_{\varphi(i_1) \varphi(i_2)}Y_{\varphi(i_2) \varphi(i_3)} \cdots Y_{\varphi(i_{k-1}) \varphi(i_k)}Y_{\varphi(i_k) \varphi(i_1)}.
  \] 

  The fact that $\{ i_{\lambda_l},i_{\lambda_{l+1}} \}$ is a self-edge 

  if (i.e. a singleton) and only if $\{ \varphi(i_{\lambda_l}),\varphi(i_{\lambda_{l+1}}) \}$ is a self-edge completes the proof.
\end{proof}
%---------%
%\begin{lemma}
%  \label{lem:equal_equiv_class_equal_expectation}
%  \notready
%  \uses{}
%  %\uses:

%  %(1)Definition of $Y_\mathbf{i}$, 
%  Given two $k$-indexes $\mathbf{i} = (i_1,...,i_k)$ and $\mathbf{i}^* = (j_1,...,j_k)$, 

%  suppose there exists a bijection $\varphi$ from the set of entries $\mathbf{i}$ onto the set of entries $\mathbf{i}^*$ such that
%  \[
%  \mathbf{i} = (i_1,...,i_k) \,\, \Longleftrightarrow \,\, \mathbf{i}^* = \bigl( \varphi(i_1),\varphi(i_2),...,\varphi(i_k) \bigl).
%  \]
%  Then $\bE (Y_\mathbf{i}) = \bE (Y_{\mathbf{i}^*})$.
%\end{lemma}
%\begin{proof}
%  It suffices to show that $Y_\mathbf{i}$ and $Y_{\mathbf{i}^*}$ represent the same number of, respectively, self-edges and connecting edges.
%  Given $Y_\mathbf{i} = Y_{i_1 i_2}Y_{i_2 i_3} \cdots Y_{i_{k-1} i_k}Y_{i_k i_1}$,
%  \[

%  Y_{\mathbf{i}^*} = Y_{j_1 j_2}Y_{j_2 j_3} \cdots Y_{j_{k-1} j_k}Y_{j_k j_1} 
%  = Y_{\varphi(i_1) \varphi(i_2)}Y_{\varphi(i_2) \varphi(i_3)} \cdots Y_{\varphi(i_{k-1}) \varphi(i_k)}Y_{\varphi(i_k) \varphi(i_1)}.
%  \] 
%  The fact that $\{ i_{\lambda_l},i_{\lambda_{l+1}} \}$ is a self-edge 

%  if (i.e. a singleton) and only if $\{ \varphi(i_{\lambda_l}),\varphi(i_{\lambda_{l+1}}) \}$ is a self-edge completes the proof.
%\end{proof}
%---------%
\begin{lemma}[Lemma 4.3 in \cite{Kemp2013RMTNotes}]
  \label{lem:lem_4.3}
  \uses{def:g_k}
  % Perhaps will need to explicitly lay out the equivalence relation.
  Given $(G,w) \in \mathcal{G}_k$, denote by $|G|$ the number of vertices in $G$. Then
  \[
  \# \{ \mathbf{i} \in [n]^k : (G_\mathbf{i},w_\mathbf{i}) = (G,w) \} = n (n-1) \cdots (n - |G| + 1).
  \]
\end{lemma}
\begin{proof}
  By the way the equivalence relation is defined in Definition \ref{def:g_k}, 

  the fact that there are $n (n - 1) \cdots (n -|G| + 1)$ ways to assign $|G|$ distinct values from $[n]$ into the indices $i_1,...,i_{|G|}$ completes the proof.
\end{proof}
%---------%
% Using Equation \ref{* *}, we can re-index the sum of Equation \ref{* *} as
%---------%
\begin{lemma}
  \label{lem:equation_4.5_1}
  \uses{def:g_k,lem:trace_expectation_of_matrix}
  \[
  \bE \Tr (\mathbf{Y}_\mathbf{i}^k) = \sum_{(G,w) \in \mathcal{G}_k} \sum_{\substack{\mathbf{i} \in [n]^k \\ (G_\mathbf{i},w_\mathbf{i}) = (G,w)}} \bE (Y_\mathbf{i}).
  \]
\end{lemma}
\begin{proof}
  Given an ordered pair $(G_\mathbf{i},w_\mathbf{i})$ generated by a $k$-index $\mathbf{i}$ and $(G,w) \in \mathcal{G}_k$, 
  only one of $(G_\mathbf{i},w_\mathbf{i}) = (G,w)$ or $(G_\mathbf{i},w_\mathbf{i}) \neq (G,w)$ holds. 

  Hence, the partition of the summation is well-defined.
\end{proof}
%---------%
\begin{lemma}
  \label{lem:equation_4.5_2}
  \uses{lem:lem_4.3,lem:equal_equiv_class_equal_expectation,lem:trace_expectation_of_matrix,lem:expectation_matrix_multi_index}
  \[
  \bE \Tr (\mathbf{Y}_\mathbf{i}^k) = \sum_{(G,w) \in \mathcal{G}_k} \Pi (G,w) \cdot \# \{ \mathbf{i} \in [n]^k : (G_\mathbf{i},w_\mathbf{i}) = (G,w) \}.
  \]
\end{lemma}
\begin{proof}
  This follows from re-indexing the sum of Lemma \ref{lem:trace_expectation_of_matrix} by using Lemma \ref{lem:expectation_matrix_multi_index}.
\end{proof}
%---------%
\begin{lemma}
  \label{lem:equation_4.5_3}
  \uses{lem:equation_4.5_1,lem:equation_4.5_2}
  \[
  \frac{1}{n} \bE \Tr (\mathbf{X}_n^k) = \sum_{(G,w) \in \mathcal{G}_k} \Pi (G,w) \cdot \frac{n (n-1) \cdots (n - |G| + 1)}{n^{k/2+1}}.
  \]
\end{lemma}
\begin{proof}
  Combining with the renormalization factor $n^{-1}$ of Proposition \ref{prop:matrix_moments_convergence}
  \[
  \frac{1}{n} \bE \Tr (\mathbf{X}_n^k) = \frac{1}{n^{k/2+1}} \bE \Tr (\mathbf{Y}_\mathbf{i}^k).
  \]
  Substituting the term $\bE \Tr (\mathbf{Y}_\mathbf{i}^k)$ with the expression in Equation \ref{lem:equation_4.5_2}
  \[
  \frac{1}{n} \bE \Tr (\mathbf{X}_n^k) = \sum_{\substack{(G,w) \in \mathcal{G}_k}} \Pi (G,w) \cdot \frac{n (n-1) \cdots (n - |G| + 1)}{n^{k/2+1}}.
  \]
\end{proof}
% Note that the summation is finite, and thus we only need to determine the values of $\Pi (G,w)$ to evaluate the summation. 

%---------%
\begin{definition}
  \label{def:g_k_ge_2}
  \uses{def:g_k}

Let $\substack{\mathcal{G}_k \\ w \geq 2}$ be a subset of $\mathcal{G}_k$ 

  in which the walk $w$ traverses each edge at least twice.
\end{definition}
%---------%
%\begin{definition}
%  \label{def:g_k_ge_2}
%  \uses{def:g_k}

%  Given an equivalence class $(G,w) \in \mathcal{G}_k$, 
%  let $\substack{\mathcal{G}_k \\ w \geq 2}$ be a subset of $\mathcal{G}_k$ 
%  in which the walk $w_\mathbf{i}$ represetned by every $(G_\mathbf{i},w_\mathbf{i}) \in (G,w)$ 

%  crosses each edge at least twice.
%\end{definition}
%---------%
%\begin{definition}
%  \label{def:Pi.graph}
%  \uses{def:g_k}
%  %uses the definition of $\Pi (G_\mathbf{i},w_\mathbf{i})$.

%  Given an equivalence class $(G,w) \in \mathcal{G}_k$, let 

%  \[
%  \Pi (G,w) = \Pi (G_\mathbf{i},w_\mathbf{i})
%  \]
%  where $(G_\mathbf{i},w_\mathbf{i}) \in (G,w)$.
%\end{definition}
%---------%
%\begin{lemma}
%  \label{lem:g_k_ge_2_wd}
%  \uses{def:g_k_ge_2,lem:equal_equiv_class_equal_expectation}
%  The set $\substack{\mathcal{G}_k \\ w \geq 2}$ in Definition \ref{def:g_k_ge_2} is well-defined.

%  Furthermore, the common value $\Pi (G,w)$ in Definition \ref{def:Pi.graph} is well-defined.  

%\end{lemma}
%\begin{proof}
%  The proof for both statements follows an identical reasoning as in the proof of Lemma \ref{lem:equal_equiv_class_equal_expectation}.
%\end{proof}
%---------%
\begin{lemma}
  \label{lem:Pi.prod_eq_zero_if_w_le_two}
  \uses{def:g_k,prop:matrix_moments_convergence,def:matrix_multi_index,def:expectation_matrix_multi_index}
  Given an ordered pair $(G,w) \in \mathcal{G}_k$, suppose there exists an edge $e \in E_\mathbf{i}$ in which it is traversed only once in the walk $w$. Then
  \[
  \Pi (G,w) = 0.
  \]
\end{lemma}
\begin{proof}

This directly follows from the assumption of Proposition \ref{prop:matrix_moments_convergence} that $\bE (Y_{ij}) = 0$ for every $i$ and $j$. 

\end{proof}
%---------%
%\begin{lemma}
%  \label{lem:Pi.prod_eq_zero_if_w_le_two}
%  \uses{def:g_k,prop:matrix_moments_convergence}
%  %uses definition of $Y_\mathbf{i}$ AND $\Pi (G,w)$.
%  Given an ordered pair $(G_\mathbf{i},w_\mathbf{i})$, suppose there exists an edge $e \in E_\mathbf{i}$ in which it is traversed only once in the walk $w_\mathbf{i}$.
%  Then
%  \[
%  \Pi (G,w) = 0.
%  \]
%\end{lemma}
%\begin{proof}

%  This directly follows from the assumption of Proposition \ref{prop:matrix_moments_convergence} that $\bE (Y_{ij}) = 0$ for every $i$ and $j$. 

%\end{proof}
%---------%
\begin{lemma}
  \label{lem:equation_4.8}
  \uses{def:g_k_ge_2,lem:equation_4.5_3,lem:Pi.prod_eq_zero_if_w_le_two,lem:expectation_matrix_multi_index,prop:matrix_moments_convergence}

  \[
  \frac{1}{n} \bE \Tr (\mathbf{X}_n^k) 
  = \sum_{(G,w) \in \substack{\mathcal{G}_k \\ w \geq 2}} \Pi (G,w) \cdot \frac{n (n-1) \cdots (n - |G| + 1)}{n^{k/2+1}}.
  \]

\end{lemma}
\begin{proof}
  Let $(G,w) \in \mathcal{G}_k$ and suppose there exists an edge $e = \{i,j\}$ such that $w(e) = 1$.
  This means, in Lemma \ref{lem:expectation_matrix_multi_index}, a singleton term $\bE (Y_{ij}^{w(e)}) = \bE (Y_{ij})$ appears.
  Following the condition of Proposition \ref{prop:matrix_moments_convergence}, the fact that the variables $Y_{ij}$ are all centered implies the product $\Pi (G,w) = 0$ for any such pair $(G,w)$.

Thus, we only need to consider those $w$ that cross each edge at least twice: 

  \[
  \frac{1}{n} \bE \Tr (\mathbf{X}_n^k) = \sum_{\substack{(G,w) \in \mathcal{G}_k}} \Pi (G,w) \cdot \frac{n (n-1) \cdots (n - |G| + 1)}{n^{k/2+1}}  = \sum_{(G,w) \in \substack{\mathcal{G}_k \\ w \geq 2}} \Pi (G,w) \cdot \frac{n (n-1) \cdots (n - |G| + 1)}{n^{k/2+1}}.
  \]
\end{proof}
%---------%
\begin{lemma}
  \label{lem:edge_set_order_leq_k_over_two}
  \uses{def:g_k_ge_2,lem:graph_walk_le_k,def:graph_edge_count}
  Given an ordered pair $(G_\mathbf{i},w_\mathbf{i})$, if $w_\mathbf{i} \geq 2$, then $\# E_\mathbf{i} \leq k/2$.
\end{lemma}
\begin{proof}
  Since $|w_\mathbf{i}| = k$, if each edge in $G_\mathbf{i}$ is traversed at least twice, then by construction the number of edges is at most $k/2$.
\end{proof}
%---------%
% This lemma might be merged with the following one(s).
% If using the equivalence definition of $\mathcal{G}_k$, it might be more convenient to introduce the Axiom of Choice to ease the notation on $(G,w)$.
%---------%







% kiran's part below

\begin{proposition}%[Exercise 4.3.1 in \cite{Kemp2013RMTNotes}]
  \label{prop:vertex_edge_inequality}
  \notready
  %\uses{}
  Let $G=(V,E)$ be a connected finite graph. Then, $|G|=\#V\le \#E+1$.
\end{proposition}

\begin{proof}
  \notready
  $|G|= \#V\le \#E+1$: proof by induction on $\#V$. Base case $\#V = 1$ is obvious. For each additional vertex, the number of edges must increase by at least one for the graph to remain connected.
\end{proof}

\begin{proposition}
  \label{prop:vertex_edge_tree_equality}
  \notready
  Let $G=(V,E)$ be a connected finite graph. Then, $|G|=\#V=\#E+1$ if and only if $G$ is a plane tree.
  \uses{prop:vertex_edge_inequality}
\end{proposition}

\begin{proof}
  \notready
  $|G|=\#V=\#E+1$ if $G$ is a plane tree is already in Lean: SimpleGraph.IsTree.card\_edgeFinset.

  $G$ is a plane tree if $|G|=\#V=\#E+1$: proof by induction on $\#V$. Base case $\#V = 1$ has no edges. Assume $\#V = \#E + 1$ for $\#V = k$. Now, consider a tree with $\#V = k+1$ nodes. Removing a leaf node leaves us with a tree with $\#V = k$ nodes. By IH, there are $k - 1$ edges. So including the leaf node gives us $k$ edges.
\end{proof}


\begin{lemma}
  \label{lemma:vertex_bound}
  \notready
  \uses{prop:vertex_edge_inequality, lem:edge_set_order_leq_k_over_two}
  For any graph $G = (V, E)$ appearing in the sum in Equation 4.8, $|G| \le k/2 + 1$.
\end{lemma}

\begin{proof}
  \notready
  Follows directly from earlier lemmas (replacing $\#E$ with $k/2$).
\end{proof}



\begin{lemma}
  \label{lemma:asc_factorial_product}
  \notready
  $n(n-1)\cdots (n-|G|+1) \le n^{|G|}$.

\end{lemma}

\begin{proof}
  \notready
  Use Nat.ascFactorial\_eq\_div. Or prove directly.
\end{proof}



\begin{lemma}
  \label{lemma:bounded_map}
  \notready
  \uses{lemma:asc_factorial_product, lemma:vertex_bound, lem:equation_4.8}
  The sequence $n\mapsto \frac1n\bE\Tr(X_n^k)$ is bounded.
\end{lemma}

\begin{proof}
  \notready
  The only part that depends on $n$ is the big fraction. Since we only care about $w \ge 2$, $|G| \le k/2 + 1$. Use the fact that the product $n(n-1)\cdots (n-|G|+1)$ is asymptotically equal to $n^{|G|}$ to conclude that the fraction is bounded and doesn't explode.
\end{proof}

\begin{lemma}
  \label{lemma:odd_vertex_bound}
  \notready
  \uses{lemma:vertex_bound}
  Suppose $k$ odd. Then, $|G| \le \frac{k}{2} + \frac{1}{2}$.
\end{lemma}

\begin{proof}
  \notready
  %prove
\end{proof}

\begin{lemma}
  \label{lemma:odd_ratio_bound}
  \notready
  \uses{lemma:odd_vertex_bound, lemma:asc_factorial_product}
  Suppose $k$ odd. Then, $\frac{n(n-1)\cdots(n-|G|+1)}{n^{k/2+1}} \le \frac{1}{\sqrt{n}}$.
\end{lemma}

\begin{proof}
  \notready
  %prove
\end{proof}




\begin{proposition}
  \label{prop:odd_case}
  \notready
  \uses{lemma:odd_ratio_bound, lem:equation_4.8}
  Suppose $k$ odd. Then, $\lim_{n\to\infty} \bE\Tr(X_n^k) = 0$.
\end{proposition}

\begin{proof}
  \notready
  Since $|G|\le \#E+1 \le k/2+1$ and $|G|$ is an integer, it follows that $|G|\le (k-1)/2+1 = k/2 + 1/2$.  Hence, in this case, all the terms in the (finite $n$-independent) sum in Equation 4.8 are $O(n^{-1/2})$
\end{proof}

\begin{lemma}
  \label{lemma:edge_bound_large_w}
  \notready
  %\uses{}
  If $k$ is even and there exists $e$ such that $w(e) \ge 3$, then $\#E \le \frac{k-1}{2}$.
\end{lemma}

\begin{proof}
  \notready
  %proof
\end{proof}



\begin{proposition}%[Proposition 4.4 in \cite{Kemp2013RMTNotes}]
  \label{prop:g_bound_self_edge}
  \notready
  \uses{prop:vertex_edge_inequality, prop:vertex_edge_tree_equality, lem:edge_set_order_leq_k_over_two}
  Let $(G,w)\in\mathcal{G}_k$ with $w\ge 2$, and suppose $k$ is even. If there exists a self-edge $e\in E_s$ in $G$, then $|G|\le k/2$.
\end{proposition}

\begin{proof}
  \notready
  Since the graph $G = (V,E)$ contains a loop, it is not a tree; it follows from Exercise \ref{ex V < E+1} that $\#V < \#E+1$.  But $w\ge 2$ implies that $\#E\le k/2$, and so $\#V < k/2+1$, and so $|G| = \#V \le k/2$.
\end{proof}

\begin{proposition}%[Proposition 4.4 in \cite{Kemp2013RMTNotes}]
  \label{prop:g_bound_large_w}
  \notready
  \uses{prop:vertex_edge_inequality, prop:vertex_edge_tree_equality, lemma:edge_bound_large_w}
  Let $(G,w)\in\mathcal{G}_k$ with $w\ge 2$, and suppose $k$ is even. If there exists an edge $e$ in $G$ with $w(e)\ge 3$, then $|G|\le k/2$.
\end{proposition}

\begin{proof}
  \notready
  The sum of $w$ over all edges $E$ in $G$ is $k$.  Hence, the sum of $w$ over $E\setminus\{e\}$ is $\le k-3$.  Since $w\ge 2$, this means that the number of edges excepting $e$ is $\le (k-3)/2$; hence, $\#E \le (k-3)/2+1 = (k-1)/2$.  By the result of a previous lemma, this means that $\#V \le (k-1)/2+1 = (k+1)/2$.  Since $k$ is even, it follows that $|G|=\#V \le k/2$.
\end{proof}




\begin{definition}
  \label{def:special_set_g}
  \notready
  %\uses{def:}
  Let $\mathcal{G}^{k/2+1}_k$ to be the set of pairs $(G,w)\in\mathcal{G}_k$ where $G$ has $k/2+1$ vertices, contains no self-edges, and the walk $w$ crosses every edge exactly $2$ times.
\end{definition}


\begin{lemma}
  \label{lemma:graph_set_finite}
  \notready
  \uses{def:g_k}
  $|G_k|$ is finite.
\end{lemma}

\begin{proof}
  \notready
  Follows from definition.
\end{proof}


\begin{lemma}
  \label{lemma:special_g_tree}
  \notready
  \uses{def:special_set_g}
  Elements of $G_k^{k/2+1}$ are trees.
\end{lemma}

\begin{proof}
  \notready
  %proof
\end{proof}

\begin{lemma}
  \label{lemma:special_g_edge_count}
  \notready
  \uses{def:special_set_g}
  Elements of $G_k^{k/2+1}$ have $|E| = k/2$.
\end{lemma}

\begin{proof}
  \notready
  %proof
\end{proof}

\begin{lemma}
  \label{lemma:special_g_vertex_count}
  \notready
  \uses{def:special_set_g, lemma:special_g_edge_count, lemma:special_set_g, prop:vertex_edge_tree_equality}
  Elements of $G_k^{k/2+1}$ have $|V| = k/2 + 1$.
\end{lemma}

\begin{proof}
  \notready
  Follows directly from dependency graph.
\end{proof}



\begin{proposition}
  \label{prop:g_difference_bound}
  \notready
  \uses{lemma:graph_set_finite, def:special_set_g, lemma:asc_factorial_product}
  $|\sum_{\mathcal{G}_{k}, w \ge 2} - \sum_{\mathcal{G}_k^{k/2+1}}| \le |\mathcal{G}_k|/n$.
\end{proposition}

\begin{proof}
  \notready
  %proof
\end{proof}



\begin{proposition}%[Equation 4.9 in \cite{Kemp2013RMTNotes}]
  \label{prop:trace_ev_special_g}
  \notready
  \uses{prop:g_difference_bound, lem:equation_4.8}
  $\frac1n\bE\Tr(X_n^k) = \sum_{(G,w)\in\mathcal{G}^{k/2+1}_k} \Pi(G,w) \cdot \frac{n(n-1)\cdots(n-|G|+1)}{n^{k/2+1}} + O_k(n^{-1})$
  %edit: remove big O notation
\end{proposition}

\begin{proof}
  \notready
  If $|G| < k/2 + 1$, then there is at least one more $n$ in the denominator than the numerator.
\end{proof}

\begin{proposition}
  \label{lemma:fraction_limit_one}
  \notready
  \uses{lemma:asc_factorial_product} %uses some lower bound stuff? might need to do more
  $\lim_{n\to\infty}\frac{n^{k/2}}{n(n-1)\cdots(n-k/2+1)} = 1$.
\end{proposition}

\begin{proof}
  \notready
  %proof
  some lower bound stuff + other stuff?
\end{proof}


\begin{proposition}
  \label{prop:trace_ev_limit_equals_sum}
  \notready
  \uses{def:special_set_g, prop:g_difference_bound, lemma:fraction_limit_one}
  $\lim_{n\to\infty}\bE\Tr(X_n^k) = \sum_{(G,w)\in\mathcal{G}^{k/2+1}_k} \Pi(G,w)$
\end{proposition}

\begin{proof}
  \notready
  Proof: use the fact that $|G|=k/2+1$ and $n(n-1)\cdots(n-k/2+1) \sim n^{k/2+1}$. Limit as n approaches infinity of $O(n^{-1/2})$ is 0.
\end{proof}




\begin{proposition}%[Equation 4.10 in \cite{Kemp2013RMTNotes}]
  \label{prop:product_g_w_to_exponential}
  \notready
  \uses{lemma:special_g_tree, lemma:special_g_edge_count, lemma:special_g_vertex_count, prop:vertex_edge_tree_equality, prop:g_bound_self_edge, prop:g_bound_large_w, prop:matrix_moments_convergence, def:expectation_matrix_multi_index} %uses: prop:matrix_moments_convergence for defn of t (but can replace)
  $\Pi(G,w) = \prod_{e_c\in E^c} \bE(Y_{12}^{w(e_c)}) = \prod_{e_c\in E^c} \bE(Y_{12}^2) = t^{\#E} = t^{k/2}$.
\end{proposition}

\begin{proof}
  \notready
  Let $(G,w)\in\mathcal{G}^{k/2+1}_k$.  Since $w$ traverses each edge exactly twice, the number of edges in $G$ is $k/2$.  Since the number of vertices is $k/2+1$, Exercise (Prop) 4.3.1 shows that $G$ is a tree.  In particular there are no self-edges (as we saw already in Proposition 4.4).

  1st equality: definition right after equation 4.4 in notes
  2nd equality: proposition 4.4 (w < 3) and previous lemma (w = 1 --> 0)
  3nd equality: definition (from main proposition)
  4th equality: number of edges is k/2.
\end{proof}




\begin{proposition}%[Proposition 4.11 in \cite{Kemp2013RMTNotes}]
  \label{prop:trace_ev_limit_equals_t_special_g}
  \notready
  \uses{prop:trace_ev_limit_equals_sum, prop:product_g_w_to_exponential}
  $\lim_{n\to\infty} \bE\Tr(X_n^k) = t^{k/2}\cdot\#\mathcal{G}_k^{k/2+1}$
\end{proposition}

\begin{proof}
  \notready
  Follows directly from 4.7.5 and 4.8.
\end{proof}

% end of kiran's part


%Haoyan part


\begin{definition}\label{def:Dyck_paths}
  A Dyck path of length $k$ is a sequence $(d_1,...,d_k) \in \{\pm 1\}^k$ such that their partial sum $\sum_{i=1}^j d_i \geq 0$
  and total sum $\sum_{i = 1}^{k}d_i = 0$. More intuitively, consider a diagonal lattice path from $(0,0)$ to $(k, 0)$ consisting of
  $\frac{k}{2}$ ups and $\frac{k}{2}$ downs such that the path never goes below thw $x$-axis.
\end{definition}


\begin{definition}\label{def:graph_to_Dyck_map}
   Define a map $\phi$ whose input is $(G, w) \in \mathcal{G}^{k/2 + 1}_k$. Then for its output,
   define a sequence $\mathbf{d}=\mathbf{d}(G,w)\in\{+1,-1\}^k$ recursively as follows.
   Let $d_1=+1$.  For $1<j\le k$, if $w_j\notin\{w_1,\ldots,w_{j-1}\}$, set $d_j=+1$; otherwise, set $d_j=-1$; then
   $\mathbf{d}(G,w) = (d_1,\ldots,d_k)$. $\phi((G,w)) = \mathbf{d}(G,w)$
\end{definition}


\begin{lemma}\label{lem:graph_Dyck_correspondence}
  \uses{def:Dyck_paths, def:graph_to_Dyck_map}
  $\phi((G,w)) = \mathbf{d}(G,w) \subseteq \mathcal{D}_k$, where $\mathcal{D}_k$ denotes the set of Dyck path of order $k$.
  \begin{proof}
    set $P_0 = (0,0)$ and $P_j = (j,d_1+\cdots+d_j)$ for $1\le j\le k$; then the piecewise linear path
    connecting $P_0,P_1,\ldots,P_k$ is a lattice path.  Since $(G,w)\in\mathcal{G}_k^2$, each edge appears exactly two times in $w$,
    meaning that the $\pm1$s come in pairs in $\mathbf{d}(G,w)$.  Hence $d_1+\cdots+d_k=0$.  What's more, for any edge $e$,
    the $-1$ assigned to its second appearance in $w$ comes {\em after} the $+1$ corresponding to its first appearance;
    this means that the partial sums $d_1+\cdots+d_j$ are all $\ge 0$.  That is: $\mathbf{d}(G,w)$ is a Dyck path
  \end{proof}
\end{lemma}


\begin{definition}\label{def:Dyck_to_graph_map}
   Define a map $\psi$ whose input is a Dyck path of order $k$: $\mathbf{d} \in \{\pm1\}^k$. Then the output is viewing
  this Dyck path as a contour reversal of a tree where an up ($d_i = 1$) corresponds to visiting a child node
  and a down ($d_i = -1$) corresponds to returning to parent node.
\end{definition}


\begin{lemma}\label{lem:Dyck_graph_correspondence}
  \uses{def:Dyck_paths, def:Dyck_to_graph_map}
  $\psi(\mathbf{d}_k) \subseteq \mathcal{G}^{k/2 + 1}_k$
  \begin{proof}
    Use induction on the order of Dyck path $k$ which is an even number. Assume $\phi(\mathbf{d}_{k-2})
    \subseteq \mathcal{G}_{k-2}^{k/2 -1}$. In the case of $k$, the last two steps appended to $\mathbf{d}_{k-2}$
    has to be $1$ followed by $-1$ in order for $\mathbf{d}_k$ to be a Dyck path. By induction hypothesis,
    this generates a graph with one extra vertex from the parent node, whose walk traversed at the last two steps of the walk.
  \end{proof}
\end{lemma}


\begin{lemma}\label{lem:composition1}
  \uses{def:Dyck_to_graph_map, def:graph_to_Dyck_map, lem:Dyck_graph_correspondence}
  $$\phi \circ \psi = id_{\mathcal{D}_k}$$
  \begin{proof}
    \uses{def:Dyck_to_graph_map, def:graph_to_Dyck_map}
    % \leanok
    Apply $\psi$ to a given Dyck path $\mathbf{d}$ by definition, then apply $\phi$ to get a new sequence
    $\mathbf{d}'$ such that $d_j' = 1$ for new vertex, $-1$ otherwise. For the original Dyck path, the new
    vertex is the up step corresponding to $1$. This implies $\phi$ recovers the original Dyck path.
  \end{proof}
\end{lemma}


\begin{lemma}\label{lem:composition2}
  \uses{def:Dyck_to_graph_map, def:graph_to_Dyck_map, lem:graph_Dyck_correspondence}
  $$\psi \circ \phi = id_{\mathcal{G}^{k/2 + 1}_k}$$
   \begin{proof}
    \uses{def:Dyck_to_graph_map, def:graph_to_Dyck_map}
    % \leanok
    The map $\psi$ recovers the graph walk structure of the input from its Dyck path by the definition.
  \end{proof}
\end{lemma}


\begin{lemma}\label{lem:walk_to_Dyck_paths_bijection}
  \uses{lem:composition1, lem:composition2}
  Let $k$ be even and let $\mathcal{D}_k$ denote the set of Dyck paths of length $k$
  \[ \mathcal{D}_k = \{(d_1,\ldots,d_k)\in\{\pm 1\}\colon \sum_{i=1}^k d_i\ge 0\text{ for }1\le j\le j\text{, and}\sum_{i=1}^kd_i=0\}. \]
  Then $(G,w)\mapsto {d}(G,w)$ is a bijection $\mathcal{G}_k^{k/2+1}\to\mathcal{D}_k$.
  \begin{proof}
    \uses{}
    obvious from the previous lemmas.
  \end{proof}
\end{lemma}

\begin{definition}\label{def:Catalan_number}
  %\lean{Combinatorics.Enumerative.Catalan}
  \[C_0 = 1, \quad \text{and for } n \geq 1, \quad C_n = \sum_{k=0}^{n-1} C_k C_{n-1-k}.\]
\end{definition}


\begin{lemma}\label{lem:binary_tree_Catalan_number}
  \uses{def:Catalan_number}
  \#\{binary trees with $k$ vertices\} is given by Catalan number $C_k$
  \begin{proof}
  \end{proof}
\end{lemma}


\begin{proposition}\label{prop:Catalan_Dyck_samecardinality}
  \uses{def:Catalan_number, def:Dyck_paths, lem:binary_tree_Catalan_number}
  %\lean{Catalan}
  % \uses{}
  %\lean{Mathlib.Combinatorics.Enumerative.Catalan}
  %\lean{DyckWord.card_dyckWord_semilength_eq_catalan}
  \[|\mathcal{D}_k| = C_{k/2} \] where $|\mathcal{D}_k|$ denotes the number of Dyke paths of length $k$ while
  $C_k$ is the $k$th Catalan number.
  \begin{proof}
    Given a binary tree with $k$ nodes, perform preorder traversal: for each internal node visited, write
    an up-step \(U = (1,1)\). For each time return from a child, write a down-step \(D = (1,-1)\).
    Since every internal node has exactly two children, there are \(k/2\) \(U\)'s and \(k/2\) \(D\)'s,
    giving a Dyke path of length \(k\). Conversely, given a Dyck path, $U$ is interpreted as adding new node
    while $D$ is returning to the parent node.
  \end{proof}
\end{proposition}

\begin{proposition}\label{prop:graph_Catalan_number}
  \uses{prop:Catalan_Dyck_samecardinality, lem:walk_to_Dyck_paths_bijection}
  \[|\mathcal{G}^{k/2 + 1}_k| = C_{k/2}\]
\end{proposition}

%end of Haoyan's part


%% BIG PROPOSITION
%
%
%
%
%
%
%
%


\begin{proposition}[Proposition 4.1 in \cite{Kemp2013RMTNotes}]
  \label{prop:matrix_moments_convergence}
  \notready
  \uses{lem:matrix_powers_entries, lem:matrix_powers_trace, def:graph_path, def:graph_edge_count, def:graph_multi_index, def:matrix_multi_index, lem:multi_index_graph_equivalence, lem:graph_walk_count_equivalence, def:graph_self_edges, def:graph_connecting_edges, prop:graph_Catalan_number}
  Let $\{Y_{ij}\}_{1\le i\le j}$ be independent random variables, with $\{Y_{ii}\}_{i\ge 1}$ identically distributed and $\{Y_{ij}\}_{1\le i<j}$ identically distributed.  Suppose that $r_k = \max\{\bE(|Y_{11}|^k),\bE(|Y_{12}|^k)\} <\infty$ for each $k\in\bN$.  Suppose further than $\bE(Y_{ij})=0$ for all $i,j$ and set $t=\bE(Y_{12}^2)$.  If $i>j$, define $Y_{ij} \equiv Y_{ji}$, and let $\mathbf{Y}_n$ be the $n\times n$ matrix with $[\mathbf{Y}_n]_{ij} = Y_{ij}$ for $1\le i,j\le n$.  Let $\mathbf{X}_n = n^{-1/2}\mathbf{Y}_n$ be the corresponding Wigner matrix.  Then
\[
\lim_{n\to\infty} \frac{1}{n}\bE\Tr(\mathbf{X}_n^k) = \begin{cases}
  t^{k/2}C_{k/2}, & k\text{ even} \\
  0, & k\text{ odd}
\end{cases}.
\]
\end{proposition}

\begin{proof}
\notready
To begin the proof, we expand the expected trace terms in terms of the entries. First, we have

$$
\frac{1}{n} \mathbb{E} \operatorname{Tr}\left(\mathbf{X}_n^k\right)=\frac{1}{n} \mathbb{E} \operatorname{Tr}\left[\left(n^{-1 / 2} \mathbf{Y}_n\right)^k\right]=n^{-k / 2-1} \mathbb{E} \operatorname{Tr}\left(\mathbf{Y}_n^k\right)
$$


From Lemma \ref{lem:matrix_powers_entries}, we have for any $1 \leq i, j \leq n$

$$
\left[\mathbf{Y}_n^k\right]_{i j}=\sum_{1 \leq i_2, \ldots, i_k \leq n} Y_{i i_2} Y_{i_2 i_3} \cdots Y_{i_{k-1} i_k} Y_{i_k j}
$$


using Lemma \ref{lem:matrix_powers_trace}:

$$
\mathbb{E} \operatorname{Tr}\left(\mathbf{Y}_n^k\right)=\sum_{i_1=1}^n \mathbb{E}\left(\left[\mathbf{Y}_n^k\right]_{i_1 i_1}\right)=\sum_{1 \leq i_1, i_2, \ldots, i_k \leq n} \mathbb{E}\left(Y_{i_1 i_2} Y_{i_2 i_3} \cdots Y_{i_k i_1}\right) \equiv \sum_{\mathbf{i} \in[n]^k} \mathbb{E}\left(Y_{\mathbf{i}}\right)
$$

where $[n]=\{1, \ldots, n\}$. For $\mathbf{i}=\left(i_1, \ldots, i_k\right)$, let $Y_{\mathbf{i}}=Y_{i_1 i_2} \cdots Y_{i_k i_1}$ be the matrix multi index from definition \ref{def:matrix_multi_index}. Using lemma \ref{lem:graph_walk_count_equivalence}, we can rewrite $Y_{\mathbf{i}}$ as:
$$
Y_{\mathbf{i}}=\prod_{1 \leq i \leq j \leq n} Y_{i j}^{w_{\mathbf{i}}(\{i, j\})}.
$$
Now, all the variables $Y_{i j}$ are independent. Using lemma \ref{lem:expectation_matrix_multi_index}, we can write the expectation of $Y_{\mathbf{i}}$ as:

$$
\mathbb{E}\left(Y_{\mathbf{i}}\right)=\prod_{1 \leq i \leq j \leq n} \mathbb{E}\left(Y_{i j}^{w_{\mathbf{i}}(\{i, j\})}\right)=\prod_{e_s \in E_{\mathbf{i}}^s} \mathbb{E}\left(Y_{11}^{w_{\mathbf{i}}\left(e_s\right)}\right) \cdot \prod_{e_c \in E_{\mathbf{i}}^c} \mathbb{E}\left(Y_{12}^{w_{\mathbf{i}}\left(e_c\right)}\right)
$$
which is equivalent to $\Pi(G_{\mathbf{i}}, w_{\mathbf{i}})$ from definition \ref{def:expectation_matrix_multi_index}.

\end{proof}

%\begin{lemma}\label{lem:trace_smul}
 %,.,,
  %\uses{????}
 % \mathlibok %what does this mean
  %\lean{Matrix.trace_smul}
 % Let $R$ be a ring with a monoid action from $\alpha$ (i.e., $\alpha$ acts distributively on $R$).
 % For any scalar $r \in \alpha$ and any square matrix $A$ over $R$, the trace of the scalar
 % multiple $r \cdot A$ equals the scalar multiple of the trace of $A$, i.e.,
 % \[ \text{tr}(r \cdot A) = r \cdot \text{tr}(A). \]
 % \end{lemma}
%
 % \begin{proof}\leanok %what does this mean
  %idk what to put in here
 % \end{proof}


% 4.2
% lemma (lemma1): using Matrix.mul_apply?? + induction?


% definition of trace
% linearity of expectation --> map_expect????
% lemma1
% defn of Y_i, [n].


% define a graph (no idea how to do this in lean)

% matrices commutative? don't really understand this part of the proof

%define \omega ({i, j})
% 4.3's statement

% 4.4: true because multiplication is commutative (EReal.mul_comm)


% more graph definitions (idk how lean would work)


% smt smt get to 4.5

% 4.6: use 4.5, scalar multiple of expectatio (Finset.smul_expect), trace of scalar multiple (Matrix.trace_smul)


% lemma 4.3: lots more work needed

%4.7: use lemma 4.3

% w >= 2 stuff
% 4.8

% 4.3.1: maybe SimpleGraph.IsTree.card_edgeFinset??

% test edit by Richard
%% test edit 2 by Richard

\section{Convergence in Probability}







%kiran's part (part 3) begins


\begin{proposition}
  \label{prop:var_trace_as_sum}
  \notready
  \uses{}
  \[ \Var\left( \frac1n\Tr(X_n^k)\right) = \sum_{(G,w,w')\in \mathcal{G}_{k,k}\atop w+w'\ge 2} \pi(G,w,w')\cdot\frac{\#\left\{(i,{j})\in [n]^{2k}\colon (G_{i\#j},w_{i},w_{j}) = (G,w,w')\right\}}{n^{k+2}}. \]
\end{proposition}

\begin{proof}
  \notready
  By construction, every edge in the joined graph $G_{{i}\#{j}}$ is traversed at least once by the union of the two paths $w_{i}$ and $w_{j}$.  Suppose that $e$ is an edge that is traversed only {\em once}.  This means that $w_{{i}\#{j}}(e) = 1$, and so it follows that the two values $w_{i}(e),w_{j}(e)$ are $\{0,1\}$.  Hence, the above expansion and the fact that $\bE(Y_{11})=\bE(Y_{12})=0$ show that $\pi(G_{{i}\#{j}},w_{i},w_{j}) = 0$ in this case.
\end{proof}


\begin{lemma}
  \label{lemma:simplified_var_trace_as_sum}
  \uses{prop:var_trace_as_sum}
  \notready
  \[ \Var\left( \frac1n\Tr({X}_n^k)\right) = \sum_{(G,w,w')\in \mathcal{G}_{k,k}\atop w+w'\ge 2} \pi(G,w,w')\cdot\frac{n(n-1)\cdots (n-|G|+1)}{n^{k+2}}. \]
\end{lemma}

\begin{proof}
  \notready
  The enumeration of the number of $2k$-tuples yielding a certain graph with two walks is the same as in the previous proposition: the structure $(G,w,w')$ specifies the $2k$-tuple precisely once we select the $|G|$ distinct indices for the vertices.  So, as before, this ratio becomes \[ \frac{n(n-1)\cdots (n-|G|+1)}{n^{k+2}}. \]
\end{proof}

\begin{proposition}
  \label{prop:var_upper_bound}
  \uses{prop:vertex_edge_inequality, lemma:simplified_var_trace_as_sum}
  \notready
  \[ \Var\left( \frac1n\Tr({X}_n^k)\right) \le \sum_{(G,w,w')\in\mathcal{G}_{k,k}\atop w+w'\ge 2} \pi(G,w,w')\cdot \frac{n^{k+1}}{n^{k+2}} \le \frac1n\cdot 2M_{2k}\cdot \#\mathcal{G}_{k,k}. \]
\end{proposition}

\begin{proof}
  \notready
  Now, we have the condition $w+w'\ge 2$, meaning every edge is traversed at least twice.  Since there are $k$ steps in each of the two paths, this means there are at most $k$ edges.  Appealing again to \ref{prop:vertex_edge_inequality}, it follows that $|G|\le k+1$.  Hence, $n(n-1)\cdots(n-|G|+1) \le n^{|G|} \le n^{k+1}$
\end{proof}

\begin{theorem}
  \label{thm:wigner_law_matrix_moments}
  \uses{prop:var_upper_bound}
  \notready
  Theorem 2.4. (Unsure if it goes in this doc.)
\end{theorem}

\begin{proof}
  \notready
  The (potentially enormous) number $B_k=2M_{2k}\cdot\#\mathcal{G}_{k,k}$ is independent of $n$, and so we have already proved that the variance is $=O_k(1/n)$.
\end{proof}







%kiran's part (part 3) ends
